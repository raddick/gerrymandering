{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#from shapely.ops import unary_union\n",
    "import pandas \n",
    "import geopandas\n",
    "import time\n",
    "\n",
    "thisyear = 2018\n",
    "\n",
    "script_dir = '/home/idies/workspace/Storage/raddick/jordanraddick.com/gerrymandering/'\n",
    "data_dir = '/home/idies/workspace/Storage/raddick/jordanraddick.com/gerrymandering/districts_with_data/'\n",
    "output_dir = data_dir\n",
    "\n",
    "acs5_dir = '/home/idies/workspace/Temporary/raddick/census_scratch/acs5/{0:.0f}/estimates/'.format(thisyear)\n",
    "shapefiledir = '/home/idies/workspace/Temporary/raddick/census_scratch/shapefiles/{0:.0f}/'.format(thisyear)\n",
    "extras_dir = '/home/idies/workspace/Storage/raddick/census/extras/'\n",
    "\n",
    "water_area_tol = 1 * 1000 * 1000\n",
    "overlap_area_tract_tol = 22000\n",
    "overlap_area_bg_tol = 4000\n",
    "#smallest tract in US is Cook County, Illinois Tract 307.02 (area = 22,094 m^2)\n",
    "#smallest block group in US is Miami-Dade County, FL, Census Tract 2703, block group 7 (area = 4,436 m^2)\n",
    "equal_area_crs = {'init': 'epsg:2163'}  # An equal area projection: https://epsg.io/2163\n",
    "\n",
    "scale = 1\n",
    "map_buffer = 0.25 # extra room on each edge of the maps, in degres\n",
    "\n",
    "#plt.rc('axes', prop_cycle=default_cycler)\n",
    "\n",
    "color_cycle = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "color_cycle = color_cycle + color_cycle\n",
    "color_cycle = color_cycle + color_cycle\n",
    "\n",
    "debug = 1\n",
    "g = 0\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get congressional district shapefiles\n",
    "\n",
    "WITH data on metro and city areas as a percentage of total district area.\n",
    "\n",
    "This assumes that you have already run <code>districts-cities.ipynb</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading congressional districts with urban/rural area data...\n",
      "Fixing at-large districts by setting district number to 1...\n",
      "Read 435 districts in 2.2 seconds.\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('reading congressional districts with urban/rural area data...')\n",
    "cd_gdf = geopandas.read_file(data_dir+'cd116_with_areas_and_types_435.shp')\n",
    "\n",
    "print('Fixing at-large districts by setting district number to 1...')\n",
    "cd_gdf.loc[cd_gdf['CD116FP'] == 0, 'CD116FP'] = 1  # At-large districts will be called District 1\n",
    "\n",
    "cd_gdf = cd_gdf.rename(columns = {'pct_metro_': 'pct_metro_area', 'pct_city_a': 'pct_city_area'})\n",
    "cd_gdf.loc[:, 'CD116FP'] = cd_gdf['CD116FP'].apply(lambda x: int(x))\n",
    "cd_gdf = cd_gdf.set_index('GEOID')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read {0:,.0f} districts in {1:,.1f} seconds.'.format(len(cd_gdf), e-s))\n",
    "#sorted(cd_gdf[cd_gdf['CD116FP'] == 0]['STUSAB'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load block groups (nationwide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tReading file 1 of 51...\n",
      "\tReading file 11 of 51...\n",
      "\tReading file 21 of 51...\n",
      "\tReading file 31 of 51...\n",
      "\tReading file 41 of 51...\n",
      "\tReading file 51 of 51...\n",
      "converting block group identifiers and coords to numeric...\n",
      "assigning GEOID as index...\n",
      "Read 217,739 census block groups in 122.6 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "bg_file_list = [shapefiledir+'BG/'+x for x in os.listdir(shapefiledir+'BG/') if ((x[-4:] == '.shp'))]\n",
    "bg_gdf = geopandas.GeoDataFrame()\n",
    "\n",
    "for i in range(0, len(bg_file_list)):\n",
    "    if (debug >= 1):\n",
    "        if ((np.mod(i,10) == 0) | (i == len(bg_file_list)-1)):\n",
    "            print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(bg_file_list)))\n",
    "    bg_gdf_i = geopandas.read_file(bg_file_list[i])\n",
    "    bg_gdf = pandas.concat((bg_gdf, bg_gdf_i), axis=0, sort=False)\n",
    "\n",
    "print('converting block group identifiers and coords to numeric...')\n",
    "bg_gdf.loc[:, 'STATEFP'] = pandas.to_numeric(bg_gdf['STATEFP'], errors='coerce')\n",
    "bg_gdf.loc[:, 'COUNTYFP'] = pandas.to_numeric(bg_gdf['COUNTYFP'], errors='coerce')\n",
    "bg_gdf.loc[:, 'TRACTCE'] = pandas.to_numeric(bg_gdf['TRACTCE'].apply(lambda x: x[0:4]+'.'+x[4:]), errors='coerce')\n",
    "bg_gdf.loc[:, 'BLKGRPCE'] = pandas.to_numeric(bg_gdf['BLKGRPCE'], errors='coerce')\n",
    "bg_gdf.loc[:, 'INTPTLAT'] = pandas.to_numeric(bg_gdf['INTPTLAT'], errors='coerce')\n",
    "bg_gdf.loc[:, 'INTPTLON'] = pandas.to_numeric(bg_gdf['INTPTLON'], errors='coerce')\n",
    "\n",
    "#bg_gdf.loc[:, 'NAME'] = pandas.to_numeric(tract_gdf['NAME'], errors='coerce')\n",
    "# bg_gdf = tract_gdf.sort_values(by='NAME')\n",
    "\n",
    "print('assigning GEOID as index...')\n",
    "bg_gdf.loc[:, 'GEOID'] = bg_gdf['GEOID'].apply(lambda x: '15000US'+str(x))\n",
    "bg_gdf = bg_gdf.set_index('GEOID')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "if (debug >= 1):\n",
    "    print('Read {0:,.0f} census block groups in {1:,.1f} seconds!'.format(len(bg_gdf), e-s))\n",
    "\n",
    "#bg_gdf.sample(1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking up state names from numbers...\n",
      "looking up county names from numbers...\n",
      "Added state and county names in 13.4 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "print('looking up state names from numbers...')\n",
    "state_codes_df = pandas.read_csv(extras_dir+'statecodes.csv')\n",
    "state_codes_df = state_codes_df.rename(columns={'STATE': 'STATEFP'})\n",
    "bg_gdf = bg_gdf.reset_index().merge(state_codes_df, how='left', on='STATEFP').set_index('GEOID')\n",
    "\n",
    "\n",
    "print('looking up county names from numbers...')\n",
    "county_names_df = pandas.read_excel(extras_dir+'all-geocodes-v2019.xlsx', header=4)\n",
    "county_names_df = county_names_df[county_names_df['Summary Level'] == 50]\n",
    "county_names_df = county_names_df.rename(columns={'State Code (FIPS)': 'STATEFP', 'County Code (FIPS)': 'COUNTYFP', 'Area Name (including legal/statistical area description)': 'COUNTY_NAME' })\n",
    "bg_gdf = bg_gdf.reset_index().merge(county_names_df[['STATEFP', 'COUNTYFP', 'COUNTY_NAME']], how='left', on=['STATEFP', 'COUNTYFP']).set_index('GEOID')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Added state and county names in {0:,.1f} seconds!'.format(e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get population data, and join onto shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ACS5 census data for 2018...\n",
      "joining population data onto block group shapefiles...\n",
      "\n",
      "added ACS5 census data to 217,739 block groups in 3 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('reading ACS5 census data for {0:.0f}...'.format(thisyear))\n",
    "acs5_estimates_df = pandas.read_csv(acs5_dir+'estimates_acs{0:}_tract_bg_gerrymandering.csv'.format(thisyear), index_col='GEOID')\n",
    "\n",
    "print('joining population data onto block group shapefiles...')\n",
    "bg_gdf = bg_gdf.join(acs5_estimates_df[['B01001_001', 'Geography Name']], how='left')\n",
    "bg_gdf = bg_gdf.rename(columns={'B01001_001': 'total_population'})\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('\\nadded ACS5 census data to {0:,.0f} block groups in {1:,.0f} seconds!'.format(len(bg_gdf), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo-match congressional districts\n",
    "\n",
    "If a tract overlaps with only one district, match that tract to its district.\n",
    "If it overlaps multiple districts, divide into block groups and match each block group to its matching districts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo-match block groups to the congressional districts they are in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get what has been matched so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading districts that have been matched so far...\n",
      "backing up...\n",
      "Kept 208,970 block groups in 0.6 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('reading districts that have been matched so far...')\n",
    "assembler_df = pandas.read_csv(data_dir+'block_group_with_district_1_2.csv', encoding='utf-8', index_col='GEOID')\n",
    "assembler_gdf = geopandas.GeoDataFrame(assembler_df.join(bg_gdf.geometry))\n",
    "assembler_gdf.crs = bg_gdf.crs\n",
    "\n",
    "\n",
    "cd_gdf = cd_gdf[~cd_gdf['STUSAB'].isin(assembler_gdf['STUSAB'].drop_duplicates().tolist())]\n",
    "bg_gdf = bg_gdf[~bg_gdf['STUSAB'].isin(assembler_gdf['STUSAB'].drop_duplicates().tolist())]\n",
    "\n",
    "print('backing up...')\n",
    "cd_gdf_bk = cd_gdf\n",
    "bg_gdf_bk = bg_gdf\n",
    "assembler_gdf_bk = assembler_gdf\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Kept {0:,.0f} block groups in {1:,.1f} seconds!'.format(len(bg_gdf),e-s))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States with 3 or more districts\n",
    "\n",
    "These are harder, because first we have to know which block groups overlap multiple districts.\n",
    "\n",
    "Create a function to mark those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to mark block groups with the districts they overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined district-marking function!\n"
     ]
    }
   ],
   "source": [
    "def mark_block_groups_with_districts_bitmask_values(block_group_info_gdf, congressional_district_info_gdf, debug=0):    \n",
    "    working_with_state = block_group_info_gdf['STATE_NAME'].head(1).values[0]\n",
    "    \n",
    "    marked_s = pandas.Series()\n",
    "    \n",
    "    equal_area_crs = {'init': 'epsg:2163'}  # An equal area projection: https://epsg.io/2163\n",
    "    cnt = 0\n",
    "    if (debug > 0):    \n",
    "        print('\\tAssigning bitmask values to block groups in {0:}...'.format(working_with_state))\n",
    "    \n",
    "    for ix, thisrow in block_group_info_gdf.iterrows():    \n",
    "        bitmasker = 0\n",
    "        if (debug > 1):\n",
    "            print(ix)\n",
    "            print('\\t\\tMatching {0:}, {1:} census tract {2:}, block group {3:}...'.format(thisrow['STATE_NAME'], thisrow['COUNTY_NAME'], thisrow['TRACTCE'], thisrow['BLKGRPCE']))\n",
    "            print('\\n')\n",
    "        if ((np.mod(cnt,100) == 0) | (cnt == len(block_group_info_gdf) - 1)):\n",
    "            if (debug > 1):\n",
    "                print('\\t\\t\\tprocessing row {0:,.0f} of {1:,.0f}...'.format(cnt+1, len(bg_gdf[bg_gdf['STUSAB'] == this_state])))\n",
    "            else:\n",
    "                print('\\t\\tprocessing row {0:,.0f} of {1:,.0f}...'.format(cnt+1, len(bg_gdf[bg_gdf['STUSAB'] == this_state])))\n",
    "                \n",
    "        for jx, thatrow in congressional_district_info_gdf.iterrows():\n",
    "            if (thisrow.geometry.intersects(thatrow.geometry)):\n",
    "                this_district_overlap_area = block_group_info_gdf[block_group_info_gdf.index == ix].to_crs(equal_area_crs).geometry.values[0].intersection(congressional_district_info_gdf[congressional_district_info_gdf.index == jx].to_crs(equal_area_crs).geometry.values[0]).area\n",
    "                if (this_district_overlap_area >= overlap_area_bg_tol):\n",
    "                    bitmasker = bitmasker + 2**(thatrow['CD116FP']-1)\n",
    "                    if (debug > 1):\n",
    "                        print('\\t\\t\\t\\tIntersects District {0:.0f} with overlap area {1:,.1f} km^2...'.format(thatrow['CD116FP'], this_district_overlap_area/1000000))               \n",
    "        marked_s.loc[ix] = bitmasker\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "    return marked_s\n",
    "print('defined district-marking function!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find block group / district overlaps, assign districts to non-overlapping block groups\n",
    "\n",
    "Uses function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "\n",
      "\n",
      "Processing Nebraska...\n",
      "\tAssigning bitmask values to block groups in Nebraska...\n",
      "\t\tprocessing row 1 of 1,633...\n",
      "\t\tprocessing row 101 of 1,633...\n",
      "\t\tprocessing row 201 of 1,633...\n",
      "\t\tprocessing row 301 of 1,633...\n",
      "\t\tprocessing row 401 of 1,633...\n",
      "\t\tprocessing row 501 of 1,633...\n",
      "\t\tprocessing row 601 of 1,633...\n",
      "\t\tprocessing row 701 of 1,633...\n",
      "\t\tprocessing row 801 of 1,633...\n",
      "\t\tprocessing row 901 of 1,633...\n",
      "\t\tprocessing row 1,001 of 1,633...\n",
      "\t\tprocessing row 1,101 of 1,633...\n",
      "\t\tprocessing row 1,201 of 1,633...\n",
      "\t\tprocessing row 1,301 of 1,633...\n",
      "\t\tprocessing row 1,401 of 1,633...\n",
      "\t\tprocessing row 1,501 of 1,633...\n",
      "\t\tprocessing row 1,601 of 1,633...\n",
      "\t\tprocessing row 1,633 of 1,633...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Nebraska to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 1,633 block groups in NE in 2 minutes 8 seconds!\n",
      "\n",
      "\n",
      "Processing New Mexico...\n",
      "\tAssigning bitmask values to block groups in New Mexico...\n",
      "\t\tprocessing row 1 of 1,449...\n",
      "\t\tprocessing row 101 of 1,449...\n",
      "\t\tprocessing row 201 of 1,449...\n",
      "\t\tprocessing row 301 of 1,449...\n",
      "\t\tprocessing row 401 of 1,449...\n",
      "\t\tprocessing row 501 of 1,449...\n",
      "\t\tprocessing row 601 of 1,449...\n",
      "\t\tprocessing row 701 of 1,449...\n",
      "\t\tprocessing row 801 of 1,449...\n",
      "\t\tprocessing row 901 of 1,449...\n",
      "\t\tprocessing row 1,001 of 1,449...\n",
      "\t\tprocessing row 1,101 of 1,449...\n",
      "\t\tprocessing row 1,201 of 1,449...\n",
      "\t\tprocessing row 1,301 of 1,449...\n",
      "\t\tprocessing row 1,401 of 1,449...\n",
      "\t\tprocessing row 1,449 of 1,449...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining New Mexico to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 1,449 block groups in NM in 1 minutes 51 seconds!\n",
      "\n",
      "\n",
      "Processing Arkansas...\n",
      "\tAssigning bitmask values to block groups in Arkansas...\n",
      "\t\tprocessing row 1 of 2,147...\n",
      "\t\tprocessing row 101 of 2,147...\n",
      "\t\tprocessing row 201 of 2,147...\n",
      "\t\tprocessing row 301 of 2,147...\n",
      "\t\tprocessing row 401 of 2,147...\n",
      "\t\tprocessing row 501 of 2,147...\n",
      "\t\tprocessing row 601 of 2,147...\n",
      "\t\tprocessing row 701 of 2,147...\n",
      "\t\tprocessing row 801 of 2,147...\n",
      "\t\tprocessing row 901 of 2,147...\n",
      "\t\tprocessing row 1,001 of 2,147...\n",
      "\t\tprocessing row 1,101 of 2,147...\n",
      "\t\tprocessing row 1,201 of 2,147...\n",
      "\t\tprocessing row 1,301 of 2,147...\n",
      "\t\tprocessing row 1,401 of 2,147...\n",
      "\t\tprocessing row 1,501 of 2,147...\n",
      "\t\tprocessing row 1,601 of 2,147...\n",
      "\t\tprocessing row 1,701 of 2,147...\n",
      "\t\tprocessing row 1,801 of 2,147...\n",
      "\t\tprocessing row 1,901 of 2,147...\n",
      "\t\tprocessing row 2,001 of 2,147...\n",
      "\t\tprocessing row 2,101 of 2,147...\n",
      "\t\tprocessing row 2,147 of 2,147...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Arkansas to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 2,147 block groups in AR in 4 minutes 49 seconds!\n",
      "\n",
      "\n",
      "Processing Kansas...\n",
      "\tAssigning bitmask values to block groups in Kansas...\n",
      "\t\tprocessing row 1 of 2,351...\n",
      "\t\tprocessing row 101 of 2,351...\n",
      "\t\tprocessing row 201 of 2,351...\n",
      "\t\tprocessing row 301 of 2,351...\n",
      "\t\tprocessing row 401 of 2,351...\n",
      "\t\tprocessing row 501 of 2,351...\n",
      "\t\tprocessing row 601 of 2,351...\n",
      "\t\tprocessing row 701 of 2,351...\n",
      "\t\tprocessing row 801 of 2,351...\n",
      "\t\tprocessing row 901 of 2,351...\n",
      "\t\tprocessing row 1,001 of 2,351...\n",
      "\t\tprocessing row 1,101 of 2,351...\n",
      "\t\tprocessing row 1,201 of 2,351...\n",
      "\t\tprocessing row 1,301 of 2,351...\n",
      "\t\tprocessing row 1,401 of 2,351...\n",
      "\t\tprocessing row 1,501 of 2,351...\n",
      "\t\tprocessing row 1,601 of 2,351...\n",
      "\t\tprocessing row 1,701 of 2,351...\n",
      "\t\tprocessing row 1,801 of 2,351...\n",
      "\t\tprocessing row 1,901 of 2,351...\n",
      "\t\tprocessing row 2,001 of 2,351...\n",
      "\t\tprocessing row 2,101 of 2,351...\n",
      "\t\tprocessing row 2,201 of 2,351...\n",
      "\t\tprocessing row 2,301 of 2,351...\n",
      "\t\tprocessing row 2,351 of 2,351...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Kansas to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 2,351 block groups in KS in 2 minutes 57 seconds!\n",
      "\n",
      "\n",
      "Processing Mississippi...\n",
      "\tAssigning bitmask values to block groups in Mississippi...\n",
      "\t\tprocessing row 1 of 2,164...\n",
      "\t\tprocessing row 101 of 2,164...\n",
      "\t\tprocessing row 201 of 2,164...\n",
      "\t\tprocessing row 301 of 2,164...\n",
      "\t\tprocessing row 401 of 2,164...\n",
      "\t\tprocessing row 501 of 2,164...\n",
      "\t\tprocessing row 601 of 2,164...\n",
      "\t\tprocessing row 701 of 2,164...\n",
      "\t\tprocessing row 801 of 2,164...\n",
      "\t\tprocessing row 901 of 2,164...\n",
      "\t\tprocessing row 1,001 of 2,164...\n",
      "\t\tprocessing row 1,101 of 2,164...\n",
      "\t\tprocessing row 1,201 of 2,164...\n",
      "\t\tprocessing row 1,301 of 2,164...\n",
      "\t\tprocessing row 1,401 of 2,164...\n",
      "\t\tprocessing row 1,501 of 2,164...\n",
      "\t\tprocessing row 1,601 of 2,164...\n",
      "\t\tprocessing row 1,701 of 2,164...\n",
      "\t\tprocessing row 1,801 of 2,164...\n",
      "\t\tprocessing row 1,901 of 2,164...\n",
      "\t\tprocessing row 2,001 of 2,164...\n",
      "\t\tprocessing row 2,101 of 2,164...\n",
      "\t\tprocessing row 2,164 of 2,164...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Mississippi to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 2,164 block groups in MS in 5 minutes 5 seconds!\n",
      "\n",
      "\n",
      "Processing Nevada...\n",
      "\tAssigning bitmask values to block groups in Nevada...\n",
      "\t\tprocessing row 1 of 1,836...\n",
      "\t\tprocessing row 101 of 1,836...\n",
      "\t\tprocessing row 201 of 1,836...\n",
      "\t\tprocessing row 301 of 1,836...\n",
      "\t\tprocessing row 401 of 1,836...\n",
      "\t\tprocessing row 501 of 1,836...\n",
      "\t\tprocessing row 601 of 1,836...\n",
      "\t\tprocessing row 701 of 1,836...\n",
      "\t\tprocessing row 801 of 1,836...\n",
      "\t\tprocessing row 901 of 1,836...\n",
      "\t\tprocessing row 1,001 of 1,836...\n",
      "\t\tprocessing row 1,101 of 1,836...\n",
      "\t\tprocessing row 1,201 of 1,836...\n",
      "\t\tprocessing row 1,301 of 1,836...\n",
      "\t\tprocessing row 1,401 of 1,836...\n",
      "\t\tprocessing row 1,501 of 1,836...\n",
      "\t\tprocessing row 1,601 of 1,836...\n",
      "\t\tprocessing row 1,701 of 1,836...\n",
      "\t\tprocessing row 1,801 of 1,836...\n",
      "\t\tprocessing row 1,836 of 1,836...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Nevada to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 1,836 block groups in NV in 1 minutes 49 seconds!\n",
      "\n",
      "\n",
      "Processing Utah...\n",
      "\tAssigning bitmask values to block groups in Utah...\n",
      "\t\tprocessing row 1 of 1,690...\n",
      "\t\tprocessing row 101 of 1,690...\n",
      "\t\tprocessing row 201 of 1,690...\n",
      "\t\tprocessing row 301 of 1,690...\n",
      "\t\tprocessing row 901 of 1,690...\n",
      "\t\tprocessing row 1,001 of 1,690...\n",
      "\t\tprocessing row 1,101 of 1,690...\n",
      "\t\tprocessing row 1,201 of 1,690...\n",
      "\t\tprocessing row 1,301 of 1,690...\n",
      "\t\tprocessing row 1,401 of 1,690...\n",
      "\t\tprocessing row 1,501 of 1,690...\n",
      "\t\tprocessing row 1,601 of 1,690...\n",
      "\t\tprocessing row 1,690 of 1,690...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Utah to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 1,690 block groups in UT in 3 minutes 59 seconds!\n",
      "\n",
      "\n",
      "Processing Connecticut...\n",
      "\tAssigning bitmask values to block groups in Connecticut...\n",
      "\t\tprocessing row 1 of 2,585...\n",
      "\t\tprocessing row 101 of 2,585...\n",
      "\t\tprocessing row 201 of 2,585...\n",
      "\t\tprocessing row 301 of 2,585...\n",
      "\t\tprocessing row 401 of 2,585...\n",
      "\t\tprocessing row 501 of 2,585...\n",
      "\t\tprocessing row 601 of 2,585...\n",
      "\t\tprocessing row 701 of 2,585...\n",
      "\t\tprocessing row 801 of 2,585...\n",
      "\t\tprocessing row 901 of 2,585...\n",
      "\t\tprocessing row 1,001 of 2,585...\n",
      "\t\tprocessing row 1,101 of 2,585...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tprocessing row 1,201 of 2,585...\n",
      "\t\tprocessing row 1,301 of 2,585...\n",
      "\t\tprocessing row 1,401 of 2,585...\n",
      "\t\tprocessing row 1,501 of 2,585...\n",
      "\t\tprocessing row 1,601 of 2,585...\n",
      "\t\tprocessing row 1,701 of 2,585...\n",
      "\t\tprocessing row 1,801 of 2,585...\n",
      "\t\tprocessing row 1,901 of 2,585...\n",
      "\t\tprocessing row 2,001 of 2,585...\n",
      "\t\tprocessing row 2,101 of 2,585...\n",
      "\t\tprocessing row 2,201 of 2,585...\n",
      "\t\tprocessing row 2,301 of 2,585...\n",
      "\t\tprocessing row 2,401 of 2,585...\n",
      "\t\tprocessing row 2,501 of 2,585...\n",
      "\t\tprocessing row 2,585 of 2,585...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Connecticut to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 2,585 block groups in CT in 1 minutes 55 seconds!\n",
      "\n",
      "\n",
      "Processing Oklahoma...\n",
      "\tAssigning bitmask values to block groups in Oklahoma...\n",
      "\t\tprocessing row 1 of 2,965...\n",
      "\t\tprocessing row 101 of 2,965...\n",
      "\t\tprocessing row 201 of 2,965...\n",
      "\t\tprocessing row 301 of 2,965...\n",
      "\t\tprocessing row 401 of 2,965...\n",
      "\t\tprocessing row 501 of 2,965...\n",
      "\t\tprocessing row 601 of 2,965...\n",
      "\t\tprocessing row 701 of 2,965...\n",
      "\t\tprocessing row 801 of 2,965...\n",
      "\t\tprocessing row 901 of 2,965...\n",
      "\t\tprocessing row 1,001 of 2,965...\n",
      "\t\tprocessing row 1,101 of 2,965...\n",
      "\t\tprocessing row 1,201 of 2,965...\n",
      "\t\tprocessing row 1,301 of 2,965...\n",
      "\t\tprocessing row 1,401 of 2,965...\n",
      "\t\tprocessing row 1,501 of 2,965...\n",
      "\t\tprocessing row 1,601 of 2,965...\n",
      "\t\tprocessing row 1,701 of 2,965...\n",
      "\t\tprocessing row 1,801 of 2,965...\n",
      "\t\tprocessing row 1,901 of 2,965...\n",
      "\t\tprocessing row 2,001 of 2,965...\n",
      "\t\tprocessing row 2,101 of 2,965...\n",
      "\t\tprocessing row 2,201 of 2,965...\n",
      "\t\tprocessing row 2,301 of 2,965...\n",
      "\t\tprocessing row 2,401 of 2,965...\n",
      "\t\tprocessing row 2,501 of 2,965...\n",
      "\t\tprocessing row 2,601 of 2,965...\n",
      "\t\tprocessing row 2,701 of 2,965...\n",
      "\t\tprocessing row 2,801 of 2,965...\n",
      "\t\tprocessing row 2,901 of 2,965...\n",
      "\t\tprocessing row 2,965 of 2,965...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Oklahoma to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 2,965 block groups in OK in 6 minutes 22 seconds!\n",
      "\n",
      "\n",
      "Processing Oregon...\n",
      "\tAssigning bitmask values to block groups in Oregon...\n",
      "\t\tprocessing row 1 of 2,634...\n",
      "\t\tprocessing row 101 of 2,634...\n",
      "\t\tprocessing row 201 of 2,634...\n",
      "\t\tprocessing row 301 of 2,634...\n",
      "\t\tprocessing row 401 of 2,634...\n",
      "\t\tprocessing row 501 of 2,634...\n",
      "\t\tprocessing row 601 of 2,634...\n",
      "\t\tprocessing row 701 of 2,634...\n",
      "\t\tprocessing row 801 of 2,634...\n",
      "\t\tprocessing row 901 of 2,634...\n",
      "\t\tprocessing row 1,001 of 2,634...\n",
      "\t\tprocessing row 1,101 of 2,634...\n",
      "\t\tprocessing row 1,201 of 2,634...\n",
      "\t\tprocessing row 1,301 of 2,634...\n",
      "\t\tprocessing row 1,401 of 2,634...\n",
      "\t\tprocessing row 1,501 of 2,634...\n",
      "\t\tprocessing row 1,601 of 2,634...\n",
      "\t\tprocessing row 1,701 of 2,634...\n",
      "\t\tprocessing row 1,801 of 2,634...\n",
      "\t\tprocessing row 1,901 of 2,634...\n",
      "\t\tprocessing row 2,001 of 2,634...\n",
      "\t\tprocessing row 2,101 of 2,634...\n",
      "\t\tprocessing row 2,201 of 2,634...\n",
      "\t\tprocessing row 2,301 of 2,634...\n",
      "\t\tprocessing row 2,401 of 2,634...\n",
      "\t\tprocessing row 2,501 of 2,634...\n",
      "\t\tprocessing row 2,601 of 2,634...\n",
      "\t\tprocessing row 2,634 of 2,634...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Oregon to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 2,634 block groups in OR in 6 minutes 14 seconds!\n",
      "\n",
      "\n",
      "Processing Kentucky...\n",
      "\tAssigning bitmask values to block groups in Kentucky...\n",
      "\t\tprocessing row 1 of 3,285...\n",
      "\t\tprocessing row 101 of 3,285...\n",
      "\t\tprocessing row 201 of 3,285...\n",
      "\t\tprocessing row 301 of 3,285...\n",
      "\t\tprocessing row 401 of 3,285...\n",
      "\t\tprocessing row 501 of 3,285...\n",
      "\t\tprocessing row 601 of 3,285...\n",
      "\t\tprocessing row 701 of 3,285...\n",
      "\t\tprocessing row 801 of 3,285...\n",
      "\t\tprocessing row 901 of 3,285...\n",
      "\t\tprocessing row 1,001 of 3,285...\n",
      "\t\tprocessing row 1,101 of 3,285...\n",
      "\t\tprocessing row 1,201 of 3,285...\n",
      "\t\tprocessing row 1,301 of 3,285...\n",
      "\t\tprocessing row 1,401 of 3,285...\n",
      "\t\tprocessing row 1,501 of 3,285...\n",
      "\t\tprocessing row 1,601 of 3,285...\n",
      "\t\tprocessing row 1,701 of 3,285...\n",
      "\t\tprocessing row 1,801 of 3,285...\n",
      "\t\tprocessing row 1,901 of 3,285...\n",
      "\t\tprocessing row 2,001 of 3,285...\n",
      "\t\tprocessing row 2,101 of 3,285...\n",
      "\t\tprocessing row 2,201 of 3,285...\n",
      "\t\tprocessing row 2,301 of 3,285...\n",
      "\t\tprocessing row 2,401 of 3,285...\n",
      "\t\tprocessing row 2,501 of 3,285...\n",
      "\t\tprocessing row 2,601 of 3,285...\n",
      "\t\tprocessing row 2,701 of 3,285...\n",
      "\t\tprocessing row 2,801 of 3,285...\n",
      "\t\tprocessing row 2,901 of 3,285...\n",
      "\t\tprocessing row 3,001 of 3,285...\n",
      "\t\tprocessing row 3,101 of 3,285...\n",
      "\t\tprocessing row 3,201 of 3,285...\n",
      "\t\tprocessing row 3,285 of 3,285...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Kentucky to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 3,285 block groups in KY in 8 minutes 20 seconds!\n",
      "\n",
      "\n",
      "Processing Louisiana...\n",
      "\tAssigning bitmask values to block groups in Louisiana...\n",
      "\t\tprocessing row 1 of 3,471...\n",
      "\t\tprocessing row 101 of 3,471...\n",
      "\t\tprocessing row 201 of 3,471...\n",
      "\t\tprocessing row 301 of 3,471...\n",
      "\t\tprocessing row 401 of 3,471...\n",
      "\t\tprocessing row 501 of 3,471...\n",
      "\t\tprocessing row 1,001 of 3,471...\n",
      "\t\tprocessing row 1,101 of 3,471...\n",
      "\t\tprocessing row 1,201 of 3,471...\n",
      "\t\tprocessing row 1,301 of 3,471...\n",
      "\t\tprocessing row 1,401 of 3,471...\n",
      "\t\tprocessing row 1,501 of 3,471...\n",
      "\t\tprocessing row 1,601 of 3,471...\n",
      "\t\tprocessing row 1,701 of 3,471...\n",
      "\t\tprocessing row 1,801 of 3,471...\n",
      "\t\tprocessing row 1,901 of 3,471...\n",
      "\t\tprocessing row 2,001 of 3,471...\n",
      "\t\tprocessing row 2,101 of 3,471...\n",
      "\t\tprocessing row 2,201 of 3,471...\n",
      "\t\tprocessing row 2,301 of 3,471...\n",
      "\t\tprocessing row 2,401 of 3,471...\n",
      "\t\tprocessing row 2,501 of 3,471...\n",
      "\t\tprocessing row 2,601 of 3,471...\n",
      "\t\tprocessing row 2,701 of 3,471...\n",
      "\t\tprocessing row 2,801 of 3,471...\n",
      "\t\tprocessing row 2,901 of 3,471...\n",
      "\t\tprocessing row 3,001 of 3,471...\n",
      "\t\tprocessing row 3,101 of 3,471...\n",
      "\t\tprocessing row 3,201 of 3,471...\n",
      "\t\tprocessing row 3,301 of 3,471...\n",
      "\t\tprocessing row 3,401 of 3,471...\n",
      "\t\tprocessing row 3,471 of 3,471...\n",
      "\tconverting bitmask values to human-readable bitmasks...\n",
      "\tcounting number of districts each block group overlaps...\n",
      "\tassigning congressional district to each block group with only one overlap...\n",
      "\t...-1 otherwise...\n",
      "\tjoining Louisiana to the rest of the assembler dataframe...\n",
      "\n",
      "\n",
      "matched districts for 3,471 block groups in LA in 13 minutes 33 seconds!\n",
      "GRAND TOTAL TIME: 61 minutes 29 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "print('getting from backup...')\n",
    "bg_gdf = bg_gdf_bk\n",
    "assembler_gdf = assembler_gdf_bk\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "for this_state in ['NE', 'NM', 'AR', 'KS', 'MS', 'NV', 'UT', 'CT', 'OK', 'OR', 'KY', 'LA']:\n",
    "    s = time.time()\n",
    "    state_full_name = bg_gdf[bg_gdf['STUSAB'] == this_state]['STATE_NAME'].values[0]\n",
    "    print('\\n')\n",
    "    print('Processing {0:}...'.format(state_full_name))\n",
    "    assembler_i_gdf = bg_gdf[bg_gdf['STUSAB'] == this_state]\n",
    "\n",
    "    district_bitmask_values_s = mark_block_groups_with_districts_bitmask_values(\n",
    "        bg_gdf[bg_gdf['STUSAB'] == this_state][['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population', 'geometry']], \n",
    "        cd_gdf[cd_gdf['STUSAB'] == this_state][['STUSAB', 'CD116FP', 'geometry']], \n",
    "        debug\n",
    "    )\n",
    "    assembler_i_gdf = assembler_i_gdf.assign(congressional_districts_bitmask_values = district_bitmask_values_s)\n",
    "    \n",
    "    \n",
    "    if (debug > 0):\n",
    "        print('\\tconverting bitmask values to human-readable bitmasks...')        \n",
    "    nDistrictsForBitmaskeration = cd_gdf[cd_gdf['STUSAB'] == this_state]['CD116FP'].max()\n",
    "    assembler_i_gdf = assembler_i_gdf.assign(congressional_districts_bitmask = \n",
    "                                             assembler_i_gdf['congressional_districts_bitmask_values'].apply(lambda x: 'x'+np.binary_repr(int(x)).zfill(nDistrictsForBitmaskeration)[::-1])\n",
    "                                            )\n",
    "\n",
    "    if (debug > 0):\n",
    "        print('\\tcounting number of districts each block group overlaps...')        \n",
    "    \n",
    "    assembler_i_gdf = assembler_i_gdf.assign(nDistricts = \n",
    "                                             assembler_i_gdf['congressional_districts_bitmask'].apply(lambda x: x[1:].count(\"1\"))\n",
    "                                            )\n",
    "    if (debug > 0):\n",
    "        print('\\tassigning congressional district to each block group with only one overlap...')\n",
    "        \n",
    "    assembler_i_gdf = assembler_i_gdf.assign(block_based_district = np.nan)\n",
    "    assembler_i_gdf.loc[\n",
    "        assembler_i_gdf['nDistricts'] == 1, \n",
    "        'block_based_district'] = assembler_i_gdf[\n",
    "                        assembler_i_gdf['nDistricts'] == 1\n",
    "                    ]['congressional_districts_bitmask'].apply(lambda x: x.find(\"1\"))\n",
    "    \n",
    "    print('\\t...-1 otherwise...')\n",
    "    assembler_i_gdf.loc[assembler_i_gdf['nDistricts'] > 1, 'block_based_district'] = -1\n",
    "    \n",
    "    if (debug > 0):\n",
    "        print('\\tjoining {0:} to the rest of the assembler dataframe...'.format(state_full_name))\n",
    "    assembler_gdf = pandas.concat((assembler_gdf, assembler_i_gdf), axis=0, sort=False)\n",
    "    if (debug > 0):\n",
    "        print(\"\\n\")\n",
    "    e = time.time()\n",
    "    g = g + (e-s)\n",
    "\n",
    "    print('matched districts for {0:,.0f} block groups in {1:} in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(assembler_i_gdf), this_state, np.floor((e-s)/60), np.floor((e-s)%60)))\n",
    "\n",
    "# print('backing up...')\n",
    "# assembler_gdf_bk2 = assembler_gdf\n",
    "\n",
    "print('GRAND TOTAL TIME: {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor(g/60), np.floor(g%60)))\n",
    "\n",
    "# print(assembler_gdf.groupby('STUSAB').size())\n",
    "# print(assembler_gdf.groupby(['STUSAB', 'nDistricts']).size())\n",
    "#print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# assembler_gdf.sample(2).T\n",
    "\n",
    "#assembler_gdf[assembler_gdf['STUSAB'] == this_state].groupby('congressional_districts_bitmask').size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign districts to block groups that overlap multiple districts\n",
    "\n",
    "See examination sections below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning districts based on examination to block groups that overlap multiple districts...\n",
      "backing up again...\n",
      "STUSAB  block_based_district\n",
      "AK      1.0                     534\n",
      "AR      1.0                     608\n",
      "        2.0                     494\n",
      "        3.0                     450\n",
      "        4.0                     595\n",
      "                               ... \n",
      "UT      2.0                     413\n",
      "        3.0                     456\n",
      "        4.0                     390\n",
      "VT      1.0                     522\n",
      "WY      1.0                     410\n",
      "Length: 70, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Assigning districts based on examination to block groups that overlap multiple districts...')\n",
    "\n",
    "# # NEBRASKA\n",
    "assembler_gdf.loc['15000US310519778001', 'block_based_district'] = 3\n",
    "assembler_gdf.loc['15000US310519778003', 'block_based_district'] = 1\n",
    "assembler_gdf.loc['15000US311530106182', 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US311530102082', '15000US311530102051'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc['15000US311530102032', 'block_based_district'] = 2\n",
    "assembler_gdf.loc['15000US311530102033', 'block_based_district'] = 1\n",
    "assembler_gdf.loc['15000US311530106183', 'block_based_district'] = 2\n",
    "# Fix to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc['15000US311530106183', 'block_based_district'] = 1\n",
    "\n",
    "\n",
    "# # NEW MEXICO\n",
    "assembler_gdf.loc[['15000US350019407001', '15000US350010038073'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US350010046022', '15000US350010038071'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US350010040012', '15000US350010008012'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc['15000US350619703031', 'block_based_district'] = 2\n",
    "assembler_gdf.loc['15000US350619703032', 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US350619701011', '15000US350619703013'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US350619703012', '15000US350619703014', '15000US350619703022'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc['15000US350430110002', 'block_based_district'] = 3\n",
    "assembler_gdf.loc['15000US350430111002', 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US350010047461', '15000US350010047462', '15000US350019406003'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US350010047201', '15000US350010047521'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US350430111001', '15000US350430111003', '15000US350019406001', '15000US350430107022'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US350430107164', '15000US350430106011', '15000US350430106012', '15000US350430106022'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc['15000US350490103121', 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US350490103111', '15000US350490103122'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US350319731001', '15000US350319403001', '15000US350319403003', '15000US350319405001'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US350410004011'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US350410004023'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US350410002001', '15000US350410001002', '15000US350410003001', '15000US350410003002', '15000US350410003004', '15000US350410001003', '15000US350410003003'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US350410001004'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US350410001001'], 'block_based_district'] = 3\n",
    "# Fix to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc['15000US350010047201', 'block_based_district'] = 3\n",
    "\n",
    "\n",
    "# # ARKANSAS\n",
    "assembler_gdf.loc[['15000US051299701002'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US051299701003'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US050690023001', '15000US050690023002'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US050690023003', '15000US050690023004'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US050330202011', '15000US051310102012', '15000US050330202013', '15000US051310103021'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US051310103023', '15000US051310103022'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US051310101011', '15000US051310101013', '15000US051310101022', '15000US051011801003'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US051310101012', '15000US050330204011', '15000US050330204014'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US050330204012'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US050330206001', '15000US050330206002', '15000US050330206003', '15000US050330206004', '15000US051011802001'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US050330201002', '15000US050330201003', '15000US051011802003', '15000US051011802002', '15000US051011801001'], 'block_based_district'] = 4\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc[['15000US051011802002', '15000US051310101022'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US051299701002', '15000US050690025001'], 'block_based_district'] = 1\n",
    "\n",
    "\n",
    "# ##### KANSAS\n",
    "assembler_gdf.loc['15000US201459703001', 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US201211004001', '15000US201211001001', '15000US201211002002'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc['15000US201211005003', 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US201170407011', '15000US201170701821'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US201170605101', '15000US201170901861', '15000US201170901863'], 'block_based_district'] = 1\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc['15000US201459703001', 'block_based_district'] = 1\n",
    "assembler_gdf.loc['15000US201211004001', 'block_based_district'] = 2\n",
    "\n",
    "# ###### MISSISSIPPI\n",
    "assembler_gdf.loc[['15000US281059502001','15000US281059502003','15000US281059507002','15000US281059507003'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc['15000US281059502004', 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US280239501002', '15000US280239503004', '15000US280239501004', '15000US280239503002'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US280239501003', '15000US280239501005'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US280890303022', '15000US280890304002', '15000US280890304003'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US280890303024', '15000US280890309003', '15000US280890309004'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US280890301053', '15000US280490114002', '15000US280490027001'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US280890301051', '15000US280890301054', '15000US280490001001', '15000US280490004002', '15000US280490004003', '15000US280490027002', '15000US280490030003'], 'block_based_district'] = 3\n",
    "\n",
    "# #### NEVADA\n",
    "assembler_gdf.loc[['15000US320030061041'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US320030032531'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US320030029611', '15000US320030051051'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US320030068004', '15000US320030027072', '15000US320030028242', '15000US320030028272', '15000US320030050102', '15000US320030050171', '15000US320030050161', '15000US320030029621'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US320030032206', '15000US320030049172', '15000US320030003012', '15000US320030038002', '15000US320030038004'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US320030003013', '15000US320030038005', '15000US320030061042'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US320199608001', '15000US320030056134'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US320199609002', '15000US320199609004'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US320030075001', '15000US320030058231', '15000US320030032231'], 'block_based_district'] = 3\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc['15000US320030050161', 'block_based_district'] = 4\n",
    "\n",
    "# ##### UTAH\n",
    "assembler_gdf.loc['15000US490351101032', 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US490111262021','15000US490111254033', '15000US490111262041'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US490111251022','15000US490111261042'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US490111261051','15000US490111261052'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US490111262032', '15000US490351101041'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US490351101042'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US490351128233', '15000US490490022051', '15000US490490022071', '15000US490490022073'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US490351128171', '15000US490351128181', '15000US490351128102', '15000US490490101131', '15000US490490101122'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US490399723001', '15000US490399725003'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US490230102003', '15000US490230102002', '15000US490399722001', '15000US490399721004', '15000US490399721006', '15000US490351139071'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US490351135341', '15000US490351138032', '15000US490351135391', '15000US490351133074'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US490351145003', '15000US490351028021', '15000US490351044001'], 'block_based_district'] = 2\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc['15000US490351139071', 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US490351101041', '15000US490351101042'], 'block_based_district'] = 3\n",
    "\n",
    "# ##### CONNECTICUT\n",
    "assembler_gdf.loc[['15000US090039800001', '15000US090035202012'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US090035202011'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US090075412002'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US090075412001', '15000US090075413003', '15000US090075414022'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US090012105003', '15000US090093513004', '15000US090093528001', '15000US090093519001'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US090012456001', '15000US090093514003', '15000US090093528002', '15000US090093519002', '15000US090093516024', '15000US090093517002', '15000US090093516022'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US090011102011'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US090011101001', '15000US090011102012', '15000US090011102021'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US090053101001', '15000US090053102002', '15000US090053108041'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US090053106022', '15000US090053108032'], 'block_based_district'] = 1\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc[['15000US090053108041', '15000US090075412001'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US090093519002', '15000US090093516024', '15000US090093528002', '15000US090093514003', '15000US090093517002'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc['15000US090093516022', 'block_based_district'] = 5\n",
    "\n",
    "#### OKLAHOMA\n",
    "assembler_gdf.loc[['15000US401310504031', '15000US401310504091', '15000US401310504081', '15000US401310504051', '15000US401310504052'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US401310504061', '15000US401310504032'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US400370215003', '15000US400370206012'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US400370216001', '15000US400370216002'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US400173014061', '15000US400173014081'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US401091088011', '15000US401091087041'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US401091087033', '15000US401091087042', '15000US401091088021', '15000US401091088012', '15000US401091088013'], 'block_based_district'] = 4\n",
    "\n",
    "# #### OREGON\n",
    "assembler_gdf.loc[['15000US410510064042'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US410510067021', '15000US410510046012'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US410510050001', '15000US410510065012'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US410510069002', '15000US410510068011', '15000US410510065022'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US410510065011', '15000US410510058005', '15000US410510068022', '15000US410510049002'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US410510051002', '15000US410510072021'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US410333613002', '15000US410333613004', '15000US410333613003'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US410333608003'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US410030102001'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US410050242003', '15000US410050242004', '15000US410050241001', '15000US410050237002', '15000US410050237004', '15000US410510064022', '15000US410510064033', '15000US410050222071'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US410059800001', '15000US410050241002', '15000US410050241003', '15000US410050230022', '15000US410050237001', '15000US410510064041', '15000US410510089021', '15000US410050222082', '15000US410050222072'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US410050242003', '15000US410050223011', '15000US410050221081', '15000US410050230011'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US410050223022', '15000US410050223023', '15000US410050223021', '15000US410050223012'], 'block_based_district'] = 5\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc[['15000US410050223012', '15000US410050223013'], 'block_based_district'] = 3\n",
    "\n",
    "\n",
    "#### KENTUCKY\n",
    "assembler_gdf.loc[['15000US212299303002'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US212150801032', '15000US212150802003', '15000US212150802002'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US212150801021', '15000US212150801022'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US211130606002','15000US211130604001','15000US211130606001','15000US211130604004','15000US211130604005'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US211110103161', '15000US211110111021', '15000US211110115202', '15000US211110116032', '15000US211110116033'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US211110103162', '15000US211110116012', '15000US211110116011', '15000US211110116041'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US210190310024', '15000US210190310025', '15000US210190311001', '15000US210190312001', '15000US210979501001', '15000US210979503002', '15000US210979503001', '15000US210979504002', '15000US210979504003'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US210190311002'], 'block_based_district'] = 5\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc[['15000US212150801032', '15000US212150802003', '15000US212150801032', '15000US212150801032'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US212150801021', '15000US212150801022', '15000US212150802002'], 'block_based_district'] = 4\n",
    "\n",
    "\n",
    "\n",
    "#### LOUISIANA\n",
    "assembler_gdf.loc[['15000US220510278072', '15000US220510278092'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US220710017341', '15000US220710017301'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220710017372', '15000US220710017451', '15000US220710017463', '15000US220710017244', '15000US220710017254'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220710033023'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220710133021', '15000US220719800001', '15000US220710076042'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US220710065001', '15000US220710054003', '15000US220710050001'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US220710076051', '15000US220710046002'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220710119001', '15000US220710144001', '15000US220710126001', '15000US220710126002', '15000US220710125001'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US220710114001', '15000US220710125002'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220710129001'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US220710129002'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220510210002', '15000US220510246001', '15000US220510249002'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220510236003', '15000US220510242011', '15000US220510244001', '15000US220510244002', '15000US220510248003', '15000US220510238001', '15000US220510236002', '15000US220510205153'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US221059538001', '15000US221059540012'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US221059539001', '15000US221059539003', '15000US221059540021' ], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US220570218001', '15000US220570218002', '15000US220570219022', '15000US221090017002', '15000US221090015002', '15000US221090015003'], 'block_based_district'] = 1\n",
    "assembler_gdf.loc[['15000US220570210001', '15000US221090005001', '15000US221090017003'], 'block_based_district'] = 6\n",
    "assembler_gdf.loc[['15000US220950701002'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220890622001', '15000US220890623021', '15000US220890624002'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220890601001', '15000US220890624001', '15000US220890621003'], 'block_based_district'] = 6\n",
    "assembler_gdf.loc[['15000US220950703004', '15000US220950710001', '15000US220950710002'], 'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220890623011', '15000US220950702001'], 'block_based_district'] = 6\n",
    "assembler_gdf.loc[['15000US220950703002', '15000US220950703003'],  'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US221210204022', '15000US220070503003', '15000US220070505001', '15000US220330030002', '15000US220950703002', '15000US220950703003', '15000US220330034002', '15000US221210202002', '15000US221210204011', '15000US220330024002',  '15000US220330053001', '15000US220330022001', '15000US220330053002', '15000US220330025001', '15000US220330052002', '15000US220330024001', '15000US220479531013', '15000US220479531022', '15000US220070501003', '15000US220050304021'],  'block_based_district'] = 2\n",
    "assembler_gdf.loc[['15000US220479529002', '15000US220479529003', '15000US220479530003', '15000US221210204021', '15000US220330046031', '15000US221210201002', '15000US220330025003', '15000US220330016001', '15000US220330016002', '15000US220050306001', '15000US220050303001', '15000US220050303002'],  'block_based_district'] = 6\n",
    "assembler_gdf.loc[['15000US220979618002', '15000US220979618001'], 'block_based_district'] = 3\n",
    "assembler_gdf.loc[['15000US220979618003'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US220979605001', '15000US220979605002'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US220979606002', '15000US220979612001', '15000US220979618004', '15000US220979602002', '15000US220979606001'], 'block_based_district'] = 4\n",
    "assembler_gdf.loc[['15000US220979617002', '15000US220979601003', '15000US220979616001', '15000US220979606004', '15000US220979613003', '15000US220979617003'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US220379514001', '15000US220379515021', '15000US220919511004', '15000US220379516004', '15000US220379514003'], 'block_based_district'] = 5\n",
    "assembler_gdf.loc[['15000US220379516001', '15000US220379515024', '15000US220919511003'], 'block_based_district'] = 6\n",
    "# Fixes to keep districts contiguous and well-mapped to actual districts\n",
    "assembler_gdf.loc[['15000US220379515022', '15000US220379516004', '15000US220379515021', '15000US220330030002'], 'block_based_district'] = 6\n",
    "assembler_gdf.loc[['15000US220979618001'], 'block_based_district'] = 4  # was 3\n",
    "assembler_gdf.loc[['15000US221059540021'], 'block_based_district'] = 1  # was 5\n",
    "assembler_gdf.loc[['15000US220479529003'], 'block_based_district'] = 2 # was 6\n",
    "assembler_gdf.loc[['15000US220890621003'], 'block_based_district'] = 2  # was 6\n",
    "assembler_gdf.loc[['15000US220070501003'], 'block_based_district'] = 6 # was 2                   \n",
    "assembler_gdf.loc[['15000US220890622001', '15000US220050304021'], 'block_based_district'] = 6 #  was 2\n",
    "assembler_gdf.loc[['15000US220510248003'], 'block_based_district'] = 2  # was 1\n",
    "assembler_gdf.loc[['15000US220050303001', '15000US220050303002', '15000US220050306001', '15000US220050304022', '15000US220050304023'], 'block_based_district'] = 2  # was 6\n",
    "assembler_gdf.loc[['15000US220950701002'], 'block_based_district'] = 6 #  was 2\n",
    "assembler_gdf.loc[['15000US220950702001', '15000US220710144001', '15000US220710133021'], 'block_based_district'] = 2   # was 1\n",
    "assembler_gdf.loc[['15000US220510249002', '15000US220710129002'], 'block_based_district'] = 1 #  was 2\n",
    "\n",
    "\n",
    "print(\"backing up again...\")\n",
    "assembler_gdf_bk2 = assembler_gdf\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "#print('Grand total time: {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor(g/60), np.floor(g%60)))\n",
    "\n",
    "#print(assembler_gdf.groupby('congressional_districts_bitmask').size())\n",
    "print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched districts for 36,979 block groups in 0 minutes 1 seconds!\n",
      "GRAND TOTAL TIME: 75  minutes 4 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "pandas.DataFrame(assembler_gdf[[x for x in assembler_gdf.columns if x != 'geometry']]\n",
    "                ).to_csv(output_dir+'block_group_with_district_1_6.csv', encoding='utf-8')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('matched districts for {0:,.0f} block groups in {1:,.0f} minutes {2:,.0f} seconds!'.format(len(assembler_gdf), np.floor((e-s)/60), np.floor((e-s)%60)))\n",
    "\n",
    "print('GRAND TOTAL TIME: {0:,.0f}  minutes {1:,.0f} seconds!'.format(np.floor(g/60), np.floor(g%60)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36979, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = pandas.read_csv(output_dir+'block_group_with_district_1_6.csv', encoding='utf-8', index_col='GEOID')\n",
    "\n",
    "\n",
    "#z.head(1).T\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tReading file 1 of 51...\n",
      "\tReading file 11 of 51...\n",
      "\tReading file 21 of 51...\n",
      "\tReading file 31 of 51...\n",
      "\tReading file 41 of 51...\n",
      "\tReading file 51 of 51...\n",
      "done in 126.7 seconds\n",
      "converting block group identifiers to numeric...\n",
      "assigning GEOID as index...\n",
      "done in 37.6 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = time.time()\n",
    "z = pandas.read_csv(output_dir+'block_group_with_district_1_6.csv', index_col='GEOID')\n",
    "bg_file_list = [shapefiledir+'BG/'+x for x in os.listdir(shapefiledir+'BG/') if ((x[-4:] == '.shp'))]\n",
    "bg_gdf = geopandas.GeoDataFrame()\n",
    "for i in range(0, len(bg_file_list)):\n",
    "    if (debug >= 1):\n",
    "        if ((np.mod(i,10) == 0) | (i == len(bg_file_list)-1)):\n",
    "            print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(bg_file_list)))\n",
    "    bg_gdf_i = geopandas.read_file(bg_file_list[i])\n",
    "    bg_gdf = pandas.concat((bg_gdf, bg_gdf_i), axis=0, sort=False)\n",
    "e = time.time()\n",
    "print('done in {0:,.1f} seconds'.format(e-s))\n",
    "\n",
    "\n",
    "s = time.time()\n",
    "print('converting block group identifiers to numeric...')\n",
    "bg_gdf.loc[:, 'STATEFP'] = pandas.to_numeric(bg_gdf['STATEFP'], errors='coerce')\n",
    "bg_gdf.loc[:, 'COUNTYFP'] = pandas.to_numeric(bg_gdf['COUNTYFP'], errors='coerce')\n",
    "bg_gdf.loc[:, 'TRACTCE'] = pandas.to_numeric(bg_gdf['TRACTCE'].apply(lambda x: str(x)[0:4]+'.'+str(x)[4:]), errors='coerce')\n",
    "bg_gdf.loc[:, 'BLKGRPCE'] = pandas.to_numeric(bg_gdf['BLKGRPCE'], errors='coerce')\n",
    "\n",
    "\n",
    "print('assigning GEOID as index...')\n",
    "bg_gdf.loc[:, 'GEOID'] = bg_gdf['GEOID'].apply(lambda x: '15000US'+str(x))#\n",
    "bg_gdf = bg_gdf.set_index('GEOID')\n",
    "\n",
    "geopandas.GeoDataFrame(data=z.join(bg_gdf.geometry, how='left'), crs=bg_gdf.crs, geometry='geometry').plot()\n",
    "\n",
    "e = time.time()\n",
    "print('done in {0:,.1f} seconds'.format(e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine overlapping districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOUISIANA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xlimits = (-91.31833504999999, -90.59215794999997)\n",
    "# # ylimits = (30.698718250000002, 30.95965475)\n",
    "\n",
    "\n",
    "# #xlimits = (-92.14, -91.95)\n",
    "# #ylimits = (30.4, 30.65)\n",
    "\n",
    "# # 2 vs 6 BOTH CLUSTERS\n",
    "# # xlimits = (-91.26,-91.115)\n",
    "# # ylimits = (30.36,30.54)\n",
    "\n",
    "# # xlimits = (-91.27377884999999, -90.76261214999998)\n",
    "# # ylimits = (29.98451145, 30.30134555)\n",
    "\n",
    "# # xlimits =  (-91.06, -90.77)\n",
    "# # ylimits = (30.08, 30.26)\n",
    "\n",
    "# # xlimits =  (-90.932, -90.9)\n",
    "# # ylimits = (30.22, 30.25)\n",
    "\n",
    "# # xlimits = (-92.18227969999998, -92.04685429999999)\n",
    "# # ylimits = (30.292847650000002, 30.424173350000004)\n",
    "\n",
    "# xlimits = (-90.88, -90.7)\n",
    "# ylimits = (30.73, 30.94)\n",
    "\n",
    "\n",
    "\n",
    "# auto_limits = False\n",
    "# label_tracts = False\n",
    "# show_water = True\n",
    "# show_roads = 'IUSCOM'# IUSCOM\n",
    "# label_roads = True\n",
    "\n",
    "# this_state = 'LA'\n",
    "# test_this_bitmask = 'x000011'\n",
    "\n",
    "# figbasesize = 100\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {1:.3f}, {0:.3f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n",
    "\n",
    "# print('http://maps.google.com/maps?q={1:.3f},{0:.3f}&t=k'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(15,15))\n",
    "\n",
    "# # # # # # cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# # # cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# # #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "# # cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 5)].plot(ax=ax, color='yellow', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 6)].plot(ax=ax, color='brown', alpha=0.5)\n",
    "\n",
    "# # # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['COUNTY_NAME'] == 'Washington County')\n",
    "# # ].plot(ax=ax, color='none', edgecolor='white', linewidth=0.5)|\n",
    "\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# #].plot(ax=ax, color='purple', edgecolor='none', alpha=0.4)#edgecolor='purple', linewidth=4)\n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=4)\n",
    "\n",
    "# #####  add labels for block groups with overlap\n",
    "# b = []\n",
    "# for ix, thisrow in assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "#     & ((assembler_gdf['INTPTLON'] >= xlimits[0]) & (assembler_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#     & ((assembler_gdf['INTPTLAT'] >= ylimits[0]) & (assembler_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "# ].iterrows():\n",
    "#     b.append(ix)\n",
    "#     if (label_tracts):\n",
    "#         annotator = ix[-6:]\n",
    "#         plt.annotate(annotator, \n",
    "#                          (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                          (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                      color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "#                    )\n",
    "\n",
    "# # show_these_places = ['Springfield', 'Lebanon', 'St Catharine', 'Texas']\n",
    "# # place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "# if (show_water):\n",
    "#     print('plotting water...')\n",
    "#     water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "\n",
    "# print('plotting roads {0:}...'.format(show_roads))\n",
    "# for i in range(0, len(show_roads)):\n",
    "#     if (show_roads[i] == 'I'):\n",
    "#         lw = 5\n",
    "#         theroadcolor = 'black'\n",
    "#     elif (show_roads[i] == 'U'):\n",
    "#         lw = 1.5\n",
    "#         theroadcolor = 'black'\n",
    "#     elif (show_roads[i] == 'S'):\n",
    "#         lw = 1\n",
    "#         theroadcolor = 'red'\n",
    "#     else:\n",
    "#         lw = 0.5\n",
    "#         theroadcolor = 'black'\n",
    "#     roads_gdf[roads_gdf['RTTYP'] == show_roads[i]].plot(ax=ax, color=theroadcolor, linewidth=lw) \n",
    "\n",
    "# if (label_roads == True):\n",
    "#     print('labeling roads...')\n",
    "#     for ix, thisrow in roads_gdf[\n",
    "#         ( (roads_gdf.geometry.centroid.x >= xlimits[0]) & (roads_gdf.geometry.centroid.x <= xlimits[1]) )\n",
    "#         & ( (roads_gdf.geometry.centroid.y >= ylimits[0]) & (roads_gdf.geometry.centroid.y <= ylimits[1]) \n",
    "#           & (roads_gdf['FULLNAME'].notnull())\n",
    "#           )\n",
    "#     ].iterrows():\n",
    "#         if ('State Rte' in str(thisrow['FULLNAME'])):        \n",
    "#             annotator = thisrow['FULLNAME'][10:]\n",
    "#             lesize = 16\n",
    "# #         else:\n",
    "# #             annotator = thisrow['FULLNAME']\n",
    "# #             lesize = 10\n",
    "#             plt.annotate(annotator, \n",
    "#                          (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y),\n",
    "#                          (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y),\n",
    "#                          color='black', backgroundcolor='white', fontsize=lesize*scale, ha='center'\n",
    "#                         )\n",
    "\n",
    "\n",
    "# if (not(auto_limits)):\n",
    "#     plt.xlim(xlimits)\n",
    "#     plt.ylim(ylimits)\n",
    "# else:\n",
    "#     xlimits = plt.xlim()\n",
    "#     ylimits = plt.ylim()\n",
    "#     print(xlimits)\n",
    "#     print(ylimits)\n",
    "\n",
    "# plt.xticks(fontsize=18*scale)\n",
    "# plt.yticks(fontsize=18*scale)\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan, 5 = yellow, 6 = brown', fontsize=18*scale)\n",
    "# #plt.title('BG {0:}'.format('15000US220050303001'), fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# e = time.time()\n",
    "# print('\\n')\n",
    "# print(e-s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 15000US220050303001\n",
    "# # -91.25, -91.04\n",
    "# # 29.98, 30.09\n",
    "# # Block Group 15000US220070501003 intersects district 2 with percent area 33.1%\n",
    "# # Block Group 15000US220070501003 intersects district 6 with percent area 66.9%\n",
    "# # Length of block group road network in district 2: 74,111 meters\n",
    "# # Length of block group road network in district 6: 68,924 meters\n",
    "\n",
    "\n",
    "\n",
    "# # 15000US220919511003\n",
    "# # -90.86, -90.72\n",
    "# # 30.77, 30.94\n",
    "# # Block Group 15000US220919511003 intersects district 5 with percent area 57.6%\n",
    "# # Block Group 15000US220919511003 intersects district 6 with percent area 42.4%\n",
    "# # Length of block group road network in district 5: 82,398 meters\n",
    "# # Length of block group road network in district 6: 86,450 meters\n",
    "    \n",
    "    \n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1)\n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# # ][\n",
    "# #     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population']\n",
    "# # ].sort_index()\n",
    "\n",
    "# b = sorted(b)\n",
    "\n",
    "# # FURTHER INVESTIGATE 15000US220919511003\n",
    "\n",
    "# for i in range(0,len(b)):\n",
    "#     print(b[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find relative overlaps of districts in this block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_block_group = '15000US220919511003'\n",
    "\n",
    "# print('finding geometries...')\n",
    "# blogeo = assembler_gdf[assembler_gdf.index == this_block_group].to_crs(equal_area_crs).geometry.values[0]\n",
    "# cd6geo = cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 5)].to_crs(equal_area_crs).geometry.values[0]\n",
    "# cd6intgeo = blogeo.intersection(cd6geo)\n",
    "\n",
    "# cd5geo = cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 6)].to_crs(equal_area_crs).geometry.values[0]\n",
    "# cd5intgeo = blogeo.intersection(cd5geo)\n",
    "\n",
    "# print('Block Group {0:} intersects district {1:.0f} with percent area {2:.1%}'.format(this_block_group, 5, cd5intgeo.area/blogeo.area))\n",
    "# print('Block Group {0:} intersects district {1:.0f} with percent area {2:.1%}'.format(this_block_group, 6, cd6intgeo.area/blogeo.area))\n",
    "# #print(cd2intgeo.area/blogeo.area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find length of road network in each district in this block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('finding roads in this block group...')\n",
    "# cnt = 0\n",
    "# roads_included_list = []\n",
    "# for ix, thisrow in roads_gdf.to_crs(equal_area_crs).iterrows():\n",
    "#     if ((np.mod(cnt,50000) == 0) | (cnt == len(roads_gdf)-1)):\n",
    "#         print('\\tProcessing road {0:,.0f} of {1:,.0f}...'.format(cnt+1, len(roads_gdf)))\n",
    "#     cnt = cnt + 1\n",
    "#     if (thisrow.geometry.intersects(blogeo)):\n",
    "#         roads_included_list.append(thisrow.geometry.intersection(blogeo))\n",
    "# print('Got all roads...')\n",
    "\n",
    "# cd5roadsgeolist = []\n",
    "# cd5roadlength = 0\n",
    "\n",
    "# cd6roadsgeolist = []\n",
    "# cd6roadlength = 0\n",
    "\n",
    "# for x in roads_included_list:\n",
    "#     if x.intersects(cd5intgeo):\n",
    "#         cd5roadsgeolist.append(x.intersection(cd5intgeo))        \n",
    "#     if x.intersects(cd6intgeo):\n",
    "#         cd6roadsgeolist.append(x.intersection(cd6intgeo))\n",
    "# print()\n",
    "# print('Length of block group road network in district {0:.0f}: {1:,.0f} meters'.format(5,np.sum([x.length for x in cd5roadsgeolist])))\n",
    "# print('Length of block group road network in district {0:.0f}: {1:,.0f} meters'.format(6,np.sum([x.length for x in cd6roadsgeolist])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'LA')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size().sort_index(ascending=False)\n",
    "\n",
    "\n",
    "# # 1 and 2 (x110000):  38\n",
    "# # 1 and 5 (x100010):   5\n",
    "# # 1 and 6 (x100001):   9\n",
    "# # 2 and 6 (x010001):  44\n",
    "# # 3 and 4 (x001100):   3\n",
    "# # 3 and 5 (x001010):   2\n",
    "# # 4 and 5 (x000110):  11\n",
    "# # 5 and 6 (x000011):   9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'LA'\n",
    "# this_state_number = 22\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KENTUCKY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALL TOGETHER\n",
    "# xlimits = [-84.4,-84.2]\n",
    "# ylimits = [38.3,38.5]\n",
    "\n",
    "# figbasesize = 20\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_state = 'KY'\n",
    "\n",
    "# test_this_bitmask = 'x000101'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(10*scale, 14*scale))\n",
    "\n",
    "\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 5)].plot(ax=ax, color='yellow', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 6)].plot(ax=ax, color='brown', alpha=0.5)\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['COUNTY_NAME'] == 'Washington County')\n",
    "# # ].plot(ax=ax, color='none', edgecolor='white', linewidth=0.5)\n",
    "\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=5)\n",
    "\n",
    "\n",
    "# #####  add labels for block groups with overlap\n",
    "# b = []\n",
    "# for ix, thisrow in assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# ].iterrows():\n",
    "#     b.append(ix)\n",
    "# #     annotator = ix[-6:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                )\n",
    "\n",
    "# # show_these_places = ['Springfield', 'Lebanon', 'St Catharine', 'Texas']\n",
    "# # place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "    \n",
    "# # print('plotting water...')\n",
    "# # water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# print('plotting roads...')\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='black', linewidth=2) \n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# if (not(auto_limits)):\n",
    "#     plt.xlim(xlimits)\n",
    "#     plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan, 5 = yellow, 6 = brown', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1)\n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# # ][\n",
    "# #     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population']\n",
    "# # ].sort_index()\n",
    "\n",
    "# b = sorted(b)\n",
    "# for i in range(0,len(b)):\n",
    "#     print(\"'\"+b[i]+\"'\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'KY')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size().sort_index(ascending=False)\n",
    "\n",
    "# # 1 and 2 (x110000):   1\n",
    "# # 2 and 4 (x010100):   5\n",
    "# # 2 and 6 (x010001):   5\n",
    "# # 3 and 4 (x001100):   9\n",
    "# # 4 and 5 (x000110):   5\n",
    "# # 4 and 6 (x000101):   5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'KY'\n",
    "# this_state_number = 21\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OREGON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALL AREAS\n",
    "# # xlimits = [-122.78,-122.4]\n",
    "# # ylimits = [45.28,45.5]\n",
    "\n",
    "# xlimits = [-122.6,-122.48]\n",
    "# ylimits = [45.28,45.42]\n",
    "\n",
    "# figbasesize = 80\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_state = 'OR'\n",
    "\n",
    "# test_this_bitmask = 'x00101'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(9.5*scale, 11.2*scale))\n",
    "\n",
    "\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 5)].plot(ax=ax, color='yellow', alpha=0.5)\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['COUNTY_NAME'] == 'Clackamas County')\n",
    "# # ].plot(ax=ax, color='none', edgecolor='brown', linewidth=0.5)\n",
    "\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=5)\n",
    "\n",
    "\n",
    "# #####  add labels for block groups with overlap\n",
    "# b = \"'\"\n",
    "# for ix, thisrow in assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# ].iterrows():\n",
    "#     b += \"'\"+ix+\"',\"\n",
    "#     annotator = ix[-6:]\n",
    "#     plt.annotate(annotator, \n",
    "#                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "#                )\n",
    "\n",
    "# # show_these_places = ['Limestone', 'Collinsville']\n",
    "# # #place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "    \n",
    "# print('plotting water...')\n",
    "# water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# print('plotting roads...')\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='black', linewidth=2) \n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# plt.xlim(xlimits)\n",
    "# plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan, 5 = yellow', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1)\n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# # ][\n",
    "# #     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population']\n",
    "# # ].sort_index()\n",
    "\n",
    "\n",
    "# print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'OR')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size().sort_index(ascending=False)\n",
    "\n",
    "# # 1 and 3 and 5 (x10101):   1\n",
    "# # 1 and 3 (x10100):   13\n",
    "# # 2 and 4 (x01010):    4\n",
    "# # 3 and 5 (x00101):   24\n",
    "# # 4 and 5: (x00011)    1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'OR'\n",
    "# this_state_number = 41\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OKLAHOMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALL TOGETHER\n",
    "# xlimits = [-97.36,-97.2]\n",
    "# ylimits = [35.4,35.55]\n",
    "\n",
    "# figbasesize = 60\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this_state = 'OK'\n",
    "\n",
    "# test_this_bitmask = 'x00011'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(9.5*scale, 9*scale))\n",
    "\n",
    "\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 5)].plot(ax=ax, color='yellow', alpha=0.5)\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['COUNTY_NAME'] == 'Rogers County')\n",
    "# # ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=5)\n",
    "\n",
    "\n",
    "# #####  add labels for block groups with overlap\n",
    "# b = \"'\"\n",
    "# for ix, thisrow in assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# ].iterrows():\n",
    "#     b += \"'\"+ix+\"',\"\n",
    "#     #print(ix)\n",
    "# #     annotator = ix[-6:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "# # show_these_places = ['Limestone', 'Collinsville']\n",
    "# # #place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "    \n",
    "# # print('plotting water...')\n",
    "# # water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# print('plotting roads...')\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='black', linewidth=2) \n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# plt.xlim(xlimits)\n",
    "# plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan, 5 = yellow', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ][\n",
    "#     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population']\n",
    "# ].sort_index()\n",
    "\n",
    "# print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'OK')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size().sort_index(ascending=False)\n",
    "\n",
    "# # 1 and 2 (x11000)    7\n",
    "# # 1 and 3 (x10100)    4\n",
    "# # 3 and 4 (x00110)    2\n",
    "# # 4 and 5 (x00011)    7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'OK'\n",
    "# this_state_number = 40\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONNECTICUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALL TOGETHER\n",
    "# xlimits = [-73.2,-73.05]\n",
    "# ylimits = [41.775, 41.85]\n",
    "\n",
    "# # xlimits = [-112.4,-111.1]\n",
    "# # ylimits = [39.2, 40]\n",
    "\n",
    "# figbasesize = 64\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_state = 'CT'\n",
    "\n",
    "# test_this_bitmask = 'x10001'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(12*scale, 6*scale))\n",
    "\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red')\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green')\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange')\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 5)].plot(ax=ax, color='yellow')\n",
    "\n",
    "# # # assembler_gdf[\n",
    "# # #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# # #     & (assembler_gdf['COUNTY_NAME'] == 'Salt Lake County')\n",
    "# # # ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=3)\n",
    "\n",
    "\n",
    "# # #####  add labels for block groups with overlap\n",
    "# # for ix, thisrow in assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1) \n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# # ].iterrows():\n",
    "# #     print(ix)\n",
    "# #     annotator = ix[-6:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "# # show_these_places = ['Salt Lake City', 'Summit Park', 'Wanship']\n",
    "# # place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "    \n",
    "# print('plotting water...')\n",
    "# water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# print('plotting roads...')\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='black', linewidth=2) \n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# plt.xlim(xlimits)\n",
    "# plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan, 5 = yellow', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ][\n",
    "#     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population']\n",
    "# ].sort_index()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'CT')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size()\n",
    "# # 1 and 2 (x11000):    3\n",
    "# # 1 and 3 (x10100):    4\n",
    "# # 1 and 5 (x10001):    5\n",
    "# # 3 and 4 (x00110):    4\n",
    "# # 3 and 5 (x00101):    9\n",
    "# # 4 and 5 (x00011):    2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'CT'\n",
    "# this_state_number = 9\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALL TOGETHER\n",
    "# xlimits = [-112.1,-111.8]\n",
    "# ylimits = [40.6, 40.8]\n",
    "\n",
    "# # xlimits = [-112.4,-111.1]\n",
    "# # ylimits = [39.2, 40]\n",
    "\n",
    "# figbasesize = 40\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this_state = 'UT'\n",
    "\n",
    "# test_this_bitmask = 'x0101'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(12*scale, 8*scale))\n",
    "\n",
    "\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green')\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan')\n",
    "\n",
    "# # # assembler_gdf[\n",
    "# # #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# # #     & (assembler_gdf['COUNTY_NAME'] == 'Salt Lake County')\n",
    "# # # ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=3)\n",
    "\n",
    "\n",
    "# # #####  add labels for block groups with overlap\n",
    "# # for ix, thisrow in assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1) \n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# # ].iterrows():\n",
    "# #     print(ix)\n",
    "# #     annotator = ix[-6:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "# # show_these_places = ['Salt Lake City', 'Summit Park', 'Wanship']\n",
    "# # place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "    \n",
    "# # print('plotting water...')\n",
    "# # water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# print('plotting roads...')\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='black', linewidth=2) \n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# plt.xlim(xlimits)\n",
    "# plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# assembler_gdf[\n",
    "#     #(assembler_gdf.index.map(lambda x: x[-6:])) \n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# ][\n",
    "#     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population']\n",
    "# ].sort_index()\n",
    "\n",
    "# #15000US490351139071\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'UT')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size()\n",
    "\n",
    "# # 2 and 3 and 4 (x0111): 1\n",
    "# # 1 and 2 (x1100):  8\n",
    "# # 2 and 4 (x0101): 15\n",
    "# # 3 and 4 (x0011): 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'UT'\n",
    "# this_state_number = 49\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEVADA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlimits = [-115.32,-115.26]\n",
    "# ylimits = [36.15,36.2]\n",
    "# figbasesize = 96\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this_state = 'NV'\n",
    "\n",
    "# test_this_bitmask = 'x0011'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(12*scale, 12*scale))\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "# ].plot(ax=ax, column='block_based_district')\n",
    "\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='none', edgecolor='red')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='none', edgecolor='green')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='none', edgecolor='orange')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='none', edgecolor='cyan')\n",
    "\n",
    "# for ix, thisrow in cd_gdf[cd_gdf['STUSAB'] == 'this_state'].iterrows():\n",
    "#     annotator = thisrow['CD116FP']\n",
    "#     plt.annotate(annotator, \n",
    "#                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                  color='black', backgroundcolor='white', fontsize=20*scale, ha='center'\n",
    "#                 )\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['COUNTY_NAME'] == 'Clark County')\n",
    "# # ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state)\n",
    "# #     & (assembler_gdf['block_based_district'] == -1)\n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# # ].plot(ax=ax, color='none', edgecolor='purple', linewidth=3)\n",
    "\n",
    "\n",
    "\n",
    "# # #####  add labels for block groups with overlap\n",
    "# # for ix, thisrow in assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1) \n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# # ].iterrows():\n",
    "# #     print(ix)\n",
    "# #     annotator = ix[-6:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "# # show_these_places = ['Las Vegas', 'Corn Creek']\n",
    "# # place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "    \n",
    "# # print('plotting water...')\n",
    "# # water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# # # # print('plotting roads...')\n",
    "# # roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='blue', linewidth=2) \n",
    "# # roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# # roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# # roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# # plt.xlim(xlimits)\n",
    "# # plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# #plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     #(assembler_gdf.index.map(lambda x: x[-6:])) \n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1)\n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# # ][\n",
    "# #     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'total_population']\n",
    "# # ].sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'NV')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size()\n",
    "\n",
    "# # 1 and 3 and 4 (x1011): 1\n",
    "# # 1 and 3 (x1010): 11\n",
    "# # 1 and 4 (x1001):  8\n",
    "# # 2 and 4 (x0101):  3\n",
    "# # 3 AND 4 (x0011):  4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'NV'\n",
    "# this_state_number = 32\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISSISSIPPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlimits = [-90.225,-90.15]\n",
    "# ylimits = [32.26, 32.33]\n",
    "# figbasesize = 100\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # print('getting from again-backup...')\n",
    "# # assembler_gdf = assembler_gdf_bk2\n",
    "# this_state = 'MS'\n",
    "\n",
    "# test_this_bitmask = 'x0110'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(14.8*scale, 14*scale))\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "# ].plot(ax=ax, column='block_based_district', edgecolor='none')\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='none', edgecolor='red', linewidth=3)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='none', edgecolor='green', linewidth=3)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='none', edgecolor='orange', linewidth=3)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='none', edgecolor='cyan', linewidth=3)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['nDistricts'] > 1)\n",
    "# ].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "\n",
    "# #####  add labels for block-based districts\n",
    "# for ix, thisrow in cd_gdf[\n",
    "#     (cd_gdf['STUSAB'] == this_state) \n",
    "# ].iterrows():\n",
    "#     annotator = thisrow['CD116FP']\n",
    "#     plt.annotate(annotator, \n",
    "#                     (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                     (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "#                 )\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['COUNTY_NAME'] == 'Madison County')\n",
    "# # ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1) \n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# # ].plot(ax=ax, color='none', edgecolor='purple', linewidth=3)\n",
    "\n",
    "\n",
    "# # # # add labels for those block groups\n",
    "# # for ix, thisrow in assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1) \n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# # ].iterrows():\n",
    "# #     print(ix)\n",
    "# #     annotator = ix[-6:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "\n",
    "# # # show_these_places = ['Jackson', 'Tougaloo']\n",
    "# # # place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# # #     annotator = thisrow['NAME'].upper()\n",
    "# # #     plt.annotate(annotator, \n",
    "# # #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# # #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# # #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# # #                 )\n",
    "    \n",
    "    \n",
    "# # print('plotting water...')\n",
    "# # water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# # # print('plotting roads...')\n",
    "# # roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='blue', linewidth=2) \n",
    "# # # roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# # # roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# # # roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# # # plt.xlim(xlimits)\n",
    "# # # plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# #plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     #(assembler_gdf.index.map(lambda x: x[-6:])) \n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1)\n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# # ][\n",
    "# #     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'area_km2', 'total_population']\n",
    "# # ].sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'MS')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size()\n",
    "\n",
    "# # 1 and 3:  5\n",
    "# # 2 and 3:  16\n",
    "# # 3 AND 4:  6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'MS'\n",
    "# this_state_number = 28\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# # print('getting from again-backup...')\n",
    "# # assembler_gdf = assembler_gdf_bk2\n",
    "\n",
    "# print('calculating block group areas...')\n",
    "# equal_area_crs = {'init': 'epsg:2163'}  # An equal area projection: https://epsg.io/2163\n",
    "# assembler_gdf = assembler_gdf.assign(area_km2 = assembler_gdf.to_crs(equal_area_crs).geometry.area/1000000)\n",
    "\n",
    "# print('backing up...')\n",
    "# assembler_gdf_bk3 = assembler_gdf\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# print('found areas for {0:,.0f} block groups in {1:} in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(assembler_i_gdf), this_state, np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KANSAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlimits = [-97,-96.2]\n",
    "# ylimits = [39.4, 40.1]\n",
    "# figbasesize = 24\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk3\n",
    "# this_state = 'KS'\n",
    "\n",
    "# test_this_bitmask = 'x1100'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(19*scale, 17*scale))\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan', alpha=0.5)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['COUNTY_NAME'] == 'Marshall County')\n",
    "# ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=3)\n",
    "\n",
    "\n",
    "# # # add labels for those block groups\n",
    "# for ix, thisrow in assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# #    & (assembler_gdf['COUNTY_NAME'] == 'Bernalillo County')\n",
    "# ].iterrows():\n",
    "#     annotator = ix[-4:]\n",
    "#     plt.annotate(annotator, \n",
    "#                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "#                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "#                 )\n",
    "    \n",
    "# # # # print('plotting places...')\n",
    "\n",
    "# # show_these_places = ['Marysville', 'Frankfort', 'Blue Rapids']\n",
    "# # place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "    \n",
    "# #print('plotting water...')\n",
    "# #water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# # print('plotting roads...')\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='blue', linewidth=2)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# plt.xlim(xlimits)\n",
    "# plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# #    & (assembler_gdf['COUNTY_NAME'] == 'Valencia County')\n",
    "# ][\n",
    "#     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'area_km2', 'total_population']\n",
    "# ].sort_values('area_km2', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'KS')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size()\n",
    "\n",
    "# # 1 and 2:  5\n",
    "# # 1 and 4:  1\n",
    "# # 2 AND 3:  4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'KS'\n",
    "# this_state_number = 20\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate areas of tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# # print('getting from again-backup...')\n",
    "# # assembler_gdf = assembler_gdf_bk2\n",
    "\n",
    "# print('calculating block group areas...')\n",
    "# equal_area_crs = {'init': 'epsg:2163'}  # An equal area projection: https://epsg.io/2163\n",
    "# assembler_gdf = assembler_gdf.assign(area_km2 = assembler_gdf.to_crs(equal_area_crs).geometry.area/1000000)\n",
    "\n",
    "# print('backing up...')\n",
    "# assembler_gdf_bk3 = assembler_gdf\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# print('found areas for {0:,.0f} block groups in {1:} in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(assembler_i_gdf), this_state, np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk3\n",
    "\n",
    "# this_state = 'KS'\n",
    "# fig, ax = plt.subplots(1,1,figsize=(12*scale,8*scale))\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan')\n",
    "\n",
    "# # assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] == 1)].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "# # assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] > 1)].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['block_based_district'] != -1)].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['block_based_district'] == -1)].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# #water_gdf.plot(ax=ax, color='blue')\n",
    "# plt.show()\n",
    "\n",
    "# #assembler_gdf[assembler_gdf['block_based_district'] == -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARKANSAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlimits = [-93.3,-93.08]\n",
    "# ylimits = [35.95,36.1]\n",
    "# figbasesize = 48\n",
    "# #center_coords = [np.round(np.mean(xlimits[0], xlimits[1]),2), np.round(np.mean(ylimits[0], ylimits[1]),2)]\n",
    "# #aspect_ratio = '{0:.1f}:{1:.1f}'.format((xlimits[1]-xlimits[0]),(ylimits[1]-ylimits[0]))\n",
    "# #print(center_coords)\n",
    "# #print(aspect_ratio)\n",
    "# print('Center coordinates: {0:.2f}, {1:.2f}'.format((xlimits[0]+xlimits[1])/2, (ylimits[0]+ylimits[1])/2))\n",
    "# print('Aspect ratio: {0:}:{1:}'.format((xlimits[1]-xlimits[0])*figbasesize, (ylimits[1]-ylimits[0])*figbasesize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk2\n",
    "# this_state = 'AR'\n",
    "\n",
    "# test_this_bitmask = 'x0011'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(10.5*scale, 7*scale))\n",
    "\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# # cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan', alpha=0.5)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['COUNTY_NAME'] == 'Newton County')\n",
    "# ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #    & (assembler_gdf['COUNTY_NAME'] == 'McKinley County')\n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=3)\n",
    "\n",
    "\n",
    "# # # # add labels for those block groups\n",
    "# # for ix, thisrow in assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1) \n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask) \n",
    "# # #    & (assembler_gdf['COUNTY_NAME'] == 'Bernalillo County')\n",
    "# # ].iterrows():\n",
    "# #     annotator = ix[-4:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "# # # # print('plotting places...')\n",
    "\n",
    "# show_these_places = ['Jasper']\n",
    "# #place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "    \n",
    "# print('plotting water...')\n",
    "# water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# # print('plotting roads...')\n",
    "# # roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='blue', linewidth=2)\n",
    "# # roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# # 3 AND 4 LEFT SIDE\n",
    "# #xlimits = [-94.6,-94]\n",
    "# #ylimits = [34.9,35.8]\n",
    "\n",
    "# # MIDLAND/HACKETT\n",
    "# # xlimits = [-94.5,-94.1]\n",
    "# # ylimits = [34.95,35.2]\n",
    "\n",
    "# # ALMA/RUDY\n",
    "# # xlimits = [-94.31,-94.14]\n",
    "# # ylimits = [35.45,35.57]\n",
    "\n",
    "# plt.xlim(xlimits)\n",
    "# plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange, 4 = cyan', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == test_this_bitmask)\n",
    "# #    & (assembler_gdf['COUNTY_NAME'] == 'Valencia County')\n",
    "# ][\n",
    "#     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'area_km2', 'total_population']\n",
    "# ].sort_values('area_km2', ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which districts overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'AR')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size()\n",
    "\n",
    "# # 3 and 4: 24\n",
    "# # 1 and 4:  4\n",
    "# # 1 and 3:  2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, and roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'AR'\n",
    "# this_state_number = 5\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate areas of block groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk2\n",
    "\n",
    "# print('calculating block group areas...')\n",
    "# equal_area_crs = {'init': 'epsg:2163'}  # An equal area projection: https://epsg.io/2163\n",
    "# assembler_gdf = assembler_gdf.assign(area_km2 = assembler_gdf.to_crs(equal_area_crs).geometry.area/1000000)\n",
    "\n",
    "# print('backing up...')\n",
    "# assembler_gdf_bk3 = assembler_gdf\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# print('found areas for {0:,.0f} block groups in {1:} in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(assembler_i_gdf), this_state, np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk3\n",
    "\n",
    "# this_state = 'AR'\n",
    "# fig, ax = plt.subplots(1,1,figsize=(12*scale,8*scale))\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 4)].plot(ax=ax, color='cyan')\n",
    "\n",
    "# # assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] == 1)].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "# # assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] > 1)].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['block_based_district'] != -1)].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['block_based_district'] == -1)].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# #water_gdf.plot(ax=ax, color='blue')\n",
    "# plt.show()\n",
    "\n",
    "# #assembler_gdf[assembler_gdf['block_based_district'] == -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW MEXICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas, places, and roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'NM'\n",
    "# #print(state_codes_df)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "# this_state_number = 35\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n",
    "# s = time.time()\n",
    "\n",
    "# this_state = 'NM'\n",
    "# #print(state_codes_df)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "# this_state_number = 35\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "# #place_gdf.head(1)\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# this_state = 'NM'\n",
    "# #print(state_codes_df)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading roads shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "# this_state_number = 35\n",
    "\n",
    "# roads_gdf = geopandas.GeoDataFrame()\n",
    "# roads_file_list = [shapefiledir+'ROADS/'+x for x in os.listdir(shapefiledir+'ROADS/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(roads_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "#     roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "#     roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} roads in {1:,.1f} seconds!'.format(len(roads_gdf), e-s))\n",
    "\n",
    "# #roads_gdf.head(1).T\n",
    "# # Road Types: C = County, I = Interstate, M = Common name, O = Other, S = State hwy, U = US hwy\n",
    "\n",
    "# #roads_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate areas of block groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk2\n",
    "\n",
    "# print('calculating block group areas...')\n",
    "# equal_area_crs = {'init': 'epsg:2163'}  # An equal area projection: https://epsg.io/2163\n",
    "# assembler_gdf = assembler_gdf.assign(area_km2 = assembler_gdf.to_crs(equal_area_crs).geometry.area/1000000)\n",
    "\n",
    "# print('backing up...')\n",
    "# assembler_gdf_bk3 = assembler_gdf\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# print('found areas for {0:,.0f} block groups in {1:} in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(assembler_i_gdf), this_state, np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many overlap in each district?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == 'NM')\n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].groupby('congressional_districts_bitmask').size().sort_index(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk3\n",
    "\n",
    "# this_state = 'NM'\n",
    "# fig, ax = plt.subplots(1,1,figsize=(12*scale,8*scale))\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange')\n",
    "\n",
    "# # assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] == 1)].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "# # assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] > 1)].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['block_based_district'] != -1)].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['block_based_district'] == -1)].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# #water_gdf.plot(ax=ax, color='blue')\n",
    "# plt.show()\n",
    "\n",
    "# #assembler_gdf[assembler_gdf['block_based_district'] == -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk3\n",
    "# this_state = 'NM'\n",
    "\n",
    "\n",
    "# xlimits = [-104.2, -102.8]\n",
    "# ylimits = [33.9,34.7]\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(15*scale, 6*scale))\n",
    "\n",
    "# #cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "\n",
    "# # assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['COUNTY_NAME'] == 'McKinley County')\n",
    "# # ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #    & (assembler_gdf['COUNTY_NAME'] == 'McKinley County')\n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == 'x011') \n",
    "# ].plot(ax=ax, color='none', edgecolor='purple', linewidth=2)\n",
    "\n",
    "\n",
    "# # # # add labels for those block groups\n",
    "# # for ix, thisrow in assembler_gdf[\n",
    "# #     (assembler_gdf['STUSAB'] == this_state) \n",
    "# #     & (assembler_gdf['block_based_district'] == -1) \n",
    "# #     & (assembler_gdf['congressional_districts_bitmask'] == 'x011') \n",
    "# # #    & (assembler_gdf['COUNTY_NAME'] == 'Bernalillo County')\n",
    "# # ].iterrows():\n",
    "# #     annotator = ix[-4:]\n",
    "# #     plt.annotate(annotator, \n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                      (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='black', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "# # # print('plotting places...')\n",
    "\n",
    "# show_these_places = ['Portales']\n",
    "# #place_gdf[place_gdf['NAME'].isin(show_these_places)].plot(ax=ax, color='none', edgecolor='blue', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[place_gdf['NAME'].isin(show_these_places)].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  (float(thisrow['INTPTLON']), float(thisrow['INTPTLAT'])),\n",
    "# #                  color='blue', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "    \n",
    "# # print('plotting water...')\n",
    "# # water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# print('plotting roads...')\n",
    "# #roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='black', linewidth=2)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=1.5)\n",
    "# roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=1)\n",
    "# roads_gdf[roads_gdf['RTTYP'].apply(lambda x: x not in ['I', 'U', 'S'])].plot(ax=ax, color='black', linewidth=0.5)\n",
    "\n",
    "# # # # 1 vs 2 ALL OVERLAPS\n",
    "# # plt.xlim([-107.2, -106.1])\n",
    "# # plt.ylim([34.6, 35.6])\n",
    "\n",
    "# # # 1 vs 2 N BERNALILLO COUNTY\n",
    "# # plt.xlim([-106.8, -106.3])\n",
    "# # plt.ylim([34.8, 35.1])\n",
    "\n",
    "# # # VALENCIA COUNTY\n",
    "# # plt.xlim([-106.8, -106.4])\n",
    "# # plt.ylim([34.6, 34.9])\n",
    "\n",
    "# # 1 AND 3 ALL OVERLAPS\n",
    "# plt.xlim([-107.2, -106])\n",
    "# plt.ylim([34.8, 36])\n",
    "\n",
    "# #1 AND 3\n",
    "# # plt.xlim([-106.8, -106.4])\n",
    "# # plt.ylim([35.1, 35.4])\n",
    "\n",
    "# # # 1 AND 3\n",
    "# # plt.xlim([-106.77, -106.65])\n",
    "# # plt.ylim([35.15, 35.25])\n",
    "\n",
    "# #1 AND 3\n",
    "# # plt.xlim([-106.62, -106.32])\n",
    "# # plt.ylim([35.2, 35.4])\n",
    "\n",
    "# #1 AND 3\n",
    "# # plt.xlim([-106.675, -106.575])\n",
    "# # plt.ylim([35.2, 35.3])\n",
    "# #plt.xlim([-106.65, -106.55])\n",
    "# #plt.ylim([35.225, 35.325])\n",
    "# # plt.xlim([-106.3, -106])\n",
    "# # plt.ylim([35, 35.2])\n",
    "\n",
    "# # 2 VS 3 WEST\n",
    "# #plt.xlim([-109.1,-108.1])\n",
    "# #plt.ylim([34,36])\n",
    "\n",
    "# # plt.xlim([-108.95,-108.78])\n",
    "# # plt.ylim([35.02,35.12])\n",
    "\n",
    "# # 2 VS 3 EAST\n",
    "# # plt.xlim(xlimits)\n",
    "# # plt.ylim(ylimits)\n",
    "\n",
    "\n",
    "# # CLOSE-UP OF PORTALES\n",
    "# plt.xlim([-103.44, -103.29])\n",
    "# plt.ylim([34.15,34.205])\n",
    "\n",
    "# # print(np.round(np.mean([-108.95,-108.78]),2))\n",
    "# # print(np.round(np.mean([35.02,35.12]),2))\n",
    "\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == 'x011')\n",
    "# #    & (assembler_gdf['COUNTY_NAME'] == 'Valencia County')\n",
    "# ][\n",
    "#     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'area_km2', 'total_population']\n",
    "# ].sort_values('area_km2', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which block groups overlap which districts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_state = 'NM'\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['nDistricts'] > 1)\n",
    "# ].groupby('congressional_districts_bitmask').size()\n",
    "\n",
    "# # congressional_districts_bitmask\n",
    "# # x011    14\n",
    "# # x101    18\n",
    "# # x110    13\n",
    "\n",
    "# these_block_groups_list = assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state)\n",
    "#     & (assembler_gdf['congressional_districts_bitmask'] == 'x101')\n",
    "# ].index.tolist()\n",
    "# print('ok')\n",
    "\n",
    "# assembler_gdf[assembler_gdf['STUSAB'] == 'NM'].groupby('congressional_districts_bitmask').size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEBRASKA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get water areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'NE'\n",
    "# #print(state_codes_df)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading water shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "# this_state_number = 31\n",
    "\n",
    "# water_gdf = geopandas.GeoDataFrame()\n",
    "# water_file_list = [shapefiledir+'AREAWATER/'+x for x in os.listdir(shapefiledir+'AREAWATER/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(water_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_file_list)))\n",
    "#     water_gdf_i = geopandas.read_file(water_file_list[i])\n",
    "#     #water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "#     water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# water_gdf = water_gdf.set_index('HYDROID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} bodies of water in {1:,.0f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #print(assembler_gdf.groupby(['STUSAB', 'block_based_district']).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# this_state = 'NE'\n",
    "# #print(state_codes_df)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('reading place shapefiles in {0:}...'.format(this_state))\n",
    "\n",
    "# #this_state_number = state_codes_df[state_codes_df['STUSAB'] == this_state.upper()].index.values[0]\n",
    "# this_state_number = 31\n",
    "\n",
    "# place_gdf = geopandas.GeoDataFrame()\n",
    "# place_file_list = [shapefiledir+'PLACE/'+x for x in os.listdir(shapefiledir+'PLACE/') if ((x[-4:] == '.shp') and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "\n",
    "# for i in range(0, len(place_file_list)):\n",
    "#     if (debug >= 1):\n",
    "#         if ((np.mod(i,10) == 0) | (i == len(water_file_list)-1)):\n",
    "#             print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(i+1, len(place_file_list)))\n",
    "#     place_gdf_i = geopandas.read_file(place_file_list[i])\n",
    "    \n",
    "#     place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0, sort=False)\n",
    "\n",
    "# place_gdf = place_gdf.set_index('GEOID')\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     #print('Read {0:,.0f} bodies of water with area greater than or equal to {1:,.0f} km^2 in {2:,.0f} seconds!'.format(len(water_gdf), water_area_tol/(1000*1000), e-s))\n",
    "#     print('Read {0:,.0f} places in {1:,.1f} seconds!'.format(len(water_gdf), e-s))\n",
    "# #place_gdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Find which districts are overlapped between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk2\n",
    "\n",
    "# this_state = 'NM'\n",
    "# fig, ax = plt.subplots(1,1,figsize=(12*scale,8*scale))\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green')\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange')\n",
    "\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] == 1)].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "# assembler_gdf[(assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['nDistricts'] > 1)].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# #water_gdf.plot(ax=ax, color='blue')\n",
    "# plt.show()\n",
    "\n",
    "# #assembler_gdf[assembler_gdf['block_based_district'] == -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating areas of block groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk2\n",
    "\n",
    "# print('calculating block group areas...')\n",
    "# equal_area_crs = {'init': 'epsg:2163'}  # An equal area projection: https://epsg.io/2163\n",
    "# assembler_gdf = assembler_gdf.assign(area_km2 = assembler_gdf.to_crs(equal_area_crs).geometry.area/1000000)\n",
    "\n",
    "# print('backing up...')\n",
    "# assembler_gdf_bk3 = assembler_gdf\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "\n",
    "# print('found areas for {0:,.0f} block groups in {1:} in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(assembler_i_gdf), this_state, np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('getting from again-backup...')\n",
    "# assembler_gdf = assembler_gdf_bk3\n",
    "# this_state = 'NE'\n",
    "\n",
    "# fig, ax = plt.subplots(1,1,figsize=(24*scale,24*scale))\n",
    "\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 1)].plot(ax=ax, color='red', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 2)].plot(ax=ax, color='green', alpha=0.5)\n",
    "# cd_gdf[(cd_gdf['STUSAB'] == this_state) & (cd_gdf['CD116FP'] == 3)].plot(ax=ax, color='orange', alpha=0.5)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] != -1)\n",
    "#     & (assembler_gdf['COUNTY_NAME'] == 'Sarpy County')\n",
    "# ].plot(ax=ax, color='none', edgecolor='yellow', linewidth=0.5)\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) & (assembler_gdf['block_based_district'] == -1)\n",
    "# ].plot(ax=ax, color='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "\n",
    "# # # add labels for those block groups\n",
    "# for ix, thisrow in assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1) \n",
    "#     #& (assembler_gdf.index.isin(['15000US310519778001','15000US310519778003']))\n",
    "# #    & (assembler_gdf['total_population'] > 0)\n",
    "# ].iterrows():\n",
    "#     annotator = ix[-4:]\n",
    "# #     annotator += '\\n'\n",
    "#     #annotator = thisrow['Geography Name'].replace(',',\"\\n\")\n",
    "#     #annotator = thisrow['block_based_district']\n",
    "#     plt.annotate(annotator, \n",
    "#                  (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "#                  (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "#                  color='black', backgroundcolor='white', fontsize=12*scale, ha='center'\n",
    "#                 )\n",
    "    \n",
    "# # print('plotting places...')\n",
    "\n",
    "# # place_gdf.plot(ax=ax, color='none', edgecolor='purple', linewidth=2)\n",
    "# #place_gdf[place_gdf['NAME'] == 'Omaha'].plot(ax=ax, color='none', edgecolor='purple', linewidth=4)\n",
    "\n",
    "# # for ix, thisrow in place_gdf[\n",
    "# #     place_gdf['NAME'].isin(['Bellevue', 'La Vista', 'Papillion', 'La Platte', 'Cullom', 'St. Columbans'])\n",
    "# # ].iterrows():\n",
    "# #     annotator = thisrow['NAME'].upper()\n",
    "# #     plt.annotate(annotator, \n",
    "# #                  (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "# #                  (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "# #                  color='purple', backgroundcolor='white', fontsize=14*scale, ha='center'\n",
    "# #                 )\n",
    "    \n",
    "    \n",
    "# print('plotting water...')\n",
    "# water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# # # SARPY COUNTY\n",
    "# # plt.xlim([-96.4, -95.8])\n",
    "# # ##plt.xlim([-96.1, -96.4])\n",
    "# # plt.ylim([41, 41.3])\n",
    "    \n",
    "# # OMAHA AREA OVERLAPS\n",
    "# plt.xlim([-96.025, -95.9])\n",
    "# plt.ylim([41.075,41.2])\n",
    "\n",
    "# plt.title('1 = red, 2 = green, 3 = orange', fontsize=18*scale)\n",
    "# plt.show()\n",
    "\n",
    "# assembler_gdf[\n",
    "#     (assembler_gdf['STUSAB'] == this_state) \n",
    "#     & (assembler_gdf['block_based_district'] == -1)\n",
    "# ][\n",
    "#     ['STATE_NAME', 'COUNTY_NAME', 'TRACTCE', 'BLKGRPCE', 'area_km2', 'total_population']\n",
    "# ].sort_values('area_km2', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# # 15000US310519778001 = 3\n",
    "# # 15000US310519778003 = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# place_gdf[place_gdf['NAME'].apply(lambda x: 'columb' in str(x).lower())]#['Bellevue', 'La Vista', 'Papillion', 'La Platte', 'Cullom', 'St. Columbans'])]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
