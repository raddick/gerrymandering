{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "import os\n",
    "import zipfile\n",
    "#import gzip\n",
    "#import tarfile\n",
    "from pprint import pprint\n",
    "import io\n",
    "import pandas\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "import geopandas\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point, Polygon\n",
    "from matplotlib.patches import FancyBboxPatch, BoxStyle\n",
    "#import re\n",
    "from matplotlib.path import Path\n",
    "\n",
    "#these_states_dict = {'FL': {}, 'MD': {}}\n",
    "these_states_dict = {'MD': {}}\n",
    "\n",
    "pop_total_denominator = 330759736\n",
    "nDistricts = 435\n",
    "target = pop_total_denominator / nDistricts\n",
    "\n",
    "\n",
    "g = 0\n",
    "scale = 8\n",
    "map_buffer_ratio = .1\n",
    "theproj = 3857 #{'init': 'epsg:9822'}\n",
    "equal_area_crs = 2163  # An equal area projection: https://epsg.io/2163\n",
    "desired_pct_area_overlap = 0.01\n",
    "\n",
    "show_water = True\n",
    "show_roads = False\n",
    "water_area_tol = 1 * 1000 * 1000\n",
    "\n",
    "#print('Target: each district should contain {0:,.0f} people!'.format(target))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "script_dir = '/home/idies/workspace/Storage/raddick/jordanraddick.com/gerrymandering/'\n",
    "census_script_dir = '/home/idies/workspace/Storage/raddick/census/'\n",
    "basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/redistricting/2020/'\n",
    "shapefile_basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/shapefiles/2020/'\n",
    "extras_dir = '/home/idies/workspace/Storage/raddick/census/extras/'\n",
    "\n",
    "district_color_cycle = ['black', 'red', 'green', 'orange', 'cyan', 'yellow', 'pink', 'gray', 'lime', 'navajowhite', 'cornflowerblue', 'darkseagreen', 'thistle', 'tomato', 'silver', 'blueviolet', 'olive', 'peru', 'dodgerblue']\n",
    "district_color_cycle += district_color_cycle\n",
    "district_color_cycle += district_color_cycle\n",
    "\n",
    "district_contrast_color_cycle = ['black', 'green', 'red', 'navy', 'black', 'purple', 'lime', 'black', 'red', 'red', 'black', 'red', 'black', 'black', 'white', 'yellow', 'yellow', 'yellow', 'yellow']\n",
    "district_contrast_color_cycle += district_contrast_color_cycle\n",
    "district_contrast_color_cycle += district_contrast_color_cycle\n",
    "\n",
    "os.chdir(basedir)\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('Now in directory: {0:}'.format(basedir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('setting up infrastructure to plot roads...')\n",
    "# we may derive from matplotlib.patches.BoxStyle._Base class.\n",
    "# You need to override transmute method in this case.\n",
    "class shield(BoxStyle._Base):\n",
    "    \"\"\"\n",
    "    A simple box.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pad=0.3):\n",
    "        \"\"\"\n",
    "        The arguments need to be floating numbers and need to have\n",
    "        default values.\n",
    "\n",
    "         *pad*\n",
    "            amount of padding\n",
    "        \"\"\"\n",
    "\n",
    "        self.pad = pad\n",
    "        super().__init__()\n",
    "\n",
    "    def transmute(self, x0, y0, width, height, mutation_size):\n",
    "        \"\"\"\n",
    "        Given the location and size of the box, return the path of\n",
    "        the box around it.\n",
    "\n",
    "         - *x0*, *y0*, *width*, *height* : location and size of the box\n",
    "         - *mutation_size* : a reference scale for the mutation.\n",
    "\n",
    "        Often, the *mutation_size* is the font size of the text.\n",
    "        You don't need to worry about the rotation as it is\n",
    "        automatically taken care of.\n",
    "        \"\"\"\n",
    "\n",
    "        # padding\n",
    "        pad = mutation_size * self.pad\n",
    "\n",
    "        # width and height with padding added.\n",
    "        width, height = width + 2.*pad, \\\n",
    "                        height + 2.*pad,\n",
    "\n",
    "        # boundary of the padded box\n",
    "        x0, y0 = x0-pad, y0-pad,\n",
    "        x1, y1 = x0+width, y0 + height\n",
    "\n",
    "        cp = [(0.5*(x0+x1), (y0-2.*pad)), # bottom\n",
    "              (x1, y0),  # right lower-mid\n",
    "              (x1+pad, (y0+y1)/2.),  # far right mid\n",
    "              (x1, y1+pad),  # top right corner\n",
    "              ((x0+x1)/2,y1),  # dip from top\n",
    "              (x0, y1+pad),  # top left corner\n",
    "              (x0-pad, (y0+y1)/2.),    # far left mid\n",
    "              (x0, y0),  # left lower-mid\n",
    "              ((x0+x1)/2., (y0-2.*pad)),  # return to bottom\n",
    "              ((x0+x1)/2., (y0-2.*pad))]\n",
    "        \n",
    "        \n",
    "        com = [Path.MOVETO,  # start\n",
    "               Path.CURVE4, # curve to right mid\n",
    "               Path.LINETO,  # line to far right mid\n",
    "               Path.LINETO, # line to top right corner\n",
    "               Path.CURVE3,  # line to dip\n",
    "               Path.LINETO,  # line to top left corner\n",
    "               Path.CURVE4,   # curve to far left mid\n",
    "               Path.LINETO,   # line to left lower-mid\n",
    "               Path.LINETO,\n",
    "               Path.CLOSEPOLY]\n",
    "\n",
    "        path = Path(cp, com)\n",
    "\n",
    "        return path\n",
    "\n",
    "BoxStyle._style_list[\"shield\"] = shield\n",
    "\n",
    "\n",
    "\n",
    "def parse_road_name(thename):\n",
    "    try:\n",
    "        annotator = thisrow['FULLNAME'][re.search('\\d',thisrow['FULLNAME']).start():]\n",
    "    except AttributeError:\n",
    "        try: \n",
    "            annotator = thisrow['FULLNAME'][re.search('Hwy',thisrow['FULLNAME']).end():]\n",
    "        except AttributeError:\n",
    "            annotator = thisrow['FULLNAME']\n",
    "    return annotator\n",
    "\n",
    "\n",
    "road_label_format = { \n",
    "    'I': { 'labelsize': 16, 'thecolor': 'yellow', 'thebbox': dict(boxstyle=\"shield\", fc='blue', ec='orange') },     \n",
    "    'U': { 'labelsize': 14, 'thecolor': 'black', 'thebbox': dict(boxstyle=\"shield\", fc='white', ec='black') },\n",
    "    'S': { 'labelsize': 12, 'thecolor': 'black', 'thebbox': dict(boxstyle=\"square,pad=0.25\", fc='white', ec='black')},\n",
    "    'C': { 'labelsize': 10, 'thecolor': 'black', 'thebbox': dict(boxstyle=\"sawtooth,pad=0.5\", fc='white') }, \n",
    "    'M': { 'labelsize': 16, 'thecolor': 'black'},\n",
    "    'O': { 'labelsize': 11, 'thecolor': 'yellow' }\n",
    "}\n",
    "print('Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "# print('Getting data from FTP...')\n",
    "\n",
    "# ftp = FTP('ftp2.census.gov')\n",
    "# ftp.login()\n",
    "# print(ftp.getwelcome())\n",
    "\n",
    "# ftp.cwd('programs-surveys/decennial/2020/data/01-Redistricting_File--PL_94-171/')\n",
    "# for thisdir in [x for x in ftp.nlst() if (('.pdf' not in x) and ('.doc' not in x))]:\n",
    "#     print('Retrieving {0:}...'.format(thisdir))\n",
    "#     zipfiles = [x for x in ftp.nlst(thisdir)]\n",
    "#     for thisfile in zipfiles:\n",
    "#         with io.open(thisfile.split('/')[1].lower(), 'wb') as f:\n",
    "#              ftp.retrbinary('RETR {0:}'.format(thisfile), f.write)\n",
    "# ftp.quit()\n",
    "# print('Done')\n",
    "\n",
    "# os.listdir()\n",
    "#os.getcwd()\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "#print('Done in {0:.1f} seconds!'.format(e-s))\n",
    "print('Retrieved files from Census FTP!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "# for thisfile in os.listdir():\n",
    "#     with zipfile.ZipFile(thisfile, 'r') as z:\n",
    "#         print('Extracting {0:}...'.format(thisfile))\n",
    "#         z.extractall()\n",
    "# for thisfile in [x for x in os.listdir() if ('zip' in x)]:\n",
    "#     os.remove(thisfile)\n",
    "# print('Done!')\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "#print('Done in {0:.1f} seconds!'.format(e-s))\n",
    "print('Unzipped files!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many districts per state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_seats_df = pandas.read_csv(script_dir+'state_seats.csv', index_col='state_name')\n",
    "\n",
    "print('looking up state names from numbers...')\n",
    "state_codes_df = pandas.read_csv(extras_dir+'statecodes.csv')\n",
    "state_codes_df.columns = [x.lower() for x in state_codes_df.columns]\n",
    "state_codes_df = state_codes_df.set_index('state_name')\n",
    "\n",
    "#bg_df = bg_df.reset_index().merge(state_codes_df[['STATE', 'STATE_NAME']], how='left', on='STATE').set_index('GEOID')\n",
    "\n",
    "# state_seats_df = state_seats_df.reset_index().merge(\n",
    "#     geo_df[geo_df['SUMLEV'] == 40][['STATE', 'STUSAB', 'NAME']], how='left', \n",
    "#     left_on='state_name', right_on='NAME'\n",
    "# )[['STATE', 'STUSAB', 'seats_old', 'seats_new']].set_index('STATE').sort_index()\n",
    "\n",
    "# print('Found new numbers of districts for {0:,.0f} states!'.format(len(state_seats_df)))\n",
    "#state_seats_df\n",
    "#geo_df[geo_df['SUMLEV'] == 40][['STATE', 'STUSAB', 'NAME']]\n",
    "\n",
    "state_seats_df = state_seats_df.join(state_codes_df).set_index('state').sort_index()\n",
    "\n",
    "print('Got old and new numbers of districts for {0:,.0f} states in {1:.1f} seconds!'.format(len(state_seats_df), e-s))\n",
    "\n",
    "for this_state in these_states_dict.keys():\n",
    "    these_states_dict[this_state]['seats_old'] = state_seats_df[state_seats_df['stusab'] == this_state]['seats_old'].values[0]\n",
    "    these_states_dict[this_state]['seats_new'] = state_seats_df[state_seats_df['stusab'] == this_state]['seats_new'].values[0]\n",
    "#pprint(these_states_dict)\n",
    "#print('\\n')\n",
    "print('Got old and new numbers of districts for {0:,.0f} focus states in {1:.1f} seconds!'.format(len(these_states_dict), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read summary levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('setting up summary levels...')\n",
    "sumlevel_df = pandas.read_excel(script_dir+'sumlevel.xlsx')\n",
    "sumlevel_df = sumlevel_df.rename(columns={'sumlevel': 'SUMLEV'})\n",
    "sumlevel_df.index.name = 'rownumber'\n",
    "#sumlevel_df = sumlevel_df.set_index('SUMLEV')\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('Read descriptions for {0:,.0f} summary levels in {1:.1f} seconds!'.format(len(sumlevel_df), e-s))\n",
    "#sumlevel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('getting states...')\n",
    "# state_all_gdf = geopandas.read_file(shapefile_basedir+'tl_2020_us_state.shp')\n",
    "# state_all_gdf.loc[:, 'STATEFP'] = pandas.to_numeric(state_all_gdf['STATEFP'], errors='coerce')\n",
    "# #state_gdf = state_gdf[state_gdf['STATEFP'].isin(state_numbers_include_list)]\n",
    "# #state_all_gdf[~state_all_gdf['STUSPS'].isin(['DC', 'PR', 'MP', 'VI', 'AS', 'GU'])][['STATEFP', 'STUSPS', 'NAME']].sort_values(by='STUSPS')\n",
    "# state_all_gdf.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read redistricting geo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('reading redistricting geography data for focus states...')\n",
    "geofiles = []\n",
    "\n",
    "allgeofiles = [x for x in os.listdir() if (('geo' in x) and (x[-3:] == '.pl') and (x[:2] not in ['dc', 'pr', 'mp', 'vi', 'as', 'gu']))]\n",
    "for this_focus_state in list(these_states_dict.keys()):\n",
    "    geofiles += [x for x in allgeofiles if x[0:2] == this_focus_state.lower()]\n",
    "    #geofiles.append([x for x in geofiles if x[0:2] == this_focus_state.lower()])\n",
    "\n",
    "geo_df = pandas.DataFrame()\n",
    "\n",
    "for thisfile in geofiles:\n",
    "    print('\\treading {0:}...'.format(thisfile))\n",
    "    geo_df_i = pandas.read_csv(thisfile, sep='|', header=None, low_memory=False, encoding='ISO-8859-1')#, encoding='utf-8')\n",
    "    geo_df = pandas.concat((geo_df, geo_df_i), axis=0)\n",
    "    \n",
    "print('renaming columns...')\n",
    "column_names = []\n",
    "column_names += ['FILEID', 'STUSAB', 'SUMLEV', 'GEOVAR', 'GEOCOMP', 'CHARITER', 'CIFSN', 'LOGRECNO', 'GEOID']\n",
    "column_names += ['GEOCODE', 'REGION', 'DIVISION', 'STATE', 'STATENS', 'COUNTY', 'COUNTYCC', 'COUNTYNS']\n",
    "column_names += ['COUSUB', 'COUSUBCC', 'COUSUBNS']\n",
    "column_names += ['SUBMCD', 'SUBMDCC', 'SUBMCDNS', 'ESTATE', 'ESTATECC', 'ESTATENS']\n",
    "column_names += ['CONCIT', 'CONCITCC', 'CONCITNS', 'PLACE','PLACECC', 'PLACENS']\n",
    "column_names += ['TRACT', 'BLKGRP', 'BLOCK']\n",
    "column_names += ['AIANHH', 'AIANHHLI', 'AIANHHFP', 'AIANHHCC', 'AIANHHNS', 'AITS', 'AITSFP', 'AITSCC', 'AITSNS']\n",
    "column_names += ['TTRACT', 'TBLKGRP', 'ANRC', 'ANRCCC', 'ARNCNS']\n",
    "column_names += ['CBSA', 'MEMI', 'CSA', 'METDIV']\n",
    "column_names += ['NECTA', 'NMEMI', 'CNECTA', 'NECTADIV']\n",
    "column_names += ['CBSAPCI', 'NECTAPCI', 'UA', 'UATYPE', 'UR']\n",
    "column_names += ['CD116', 'CD118', 'CD119', 'CD120', 'CD121']\n",
    "column_names += ['SLDU18', 'SLDU22', 'SLDU24', 'SLDU26', 'SLDU28']\n",
    "column_names += ['SLDL18', 'SLDL22', 'SLDL24', 'SLDL26', 'SLDL28']\n",
    "column_names += ['VTD', 'VTDI', 'ZCTA', 'SDELM', 'SDSEC', 'SDUNI', 'PUMA']\n",
    "column_names += ['AREALAND', 'AREAWATER', 'BASENAME', 'NAME', 'FUNCSTAT', 'GCUNI']\n",
    "column_names += ['POP100', 'HU100']\n",
    "column_names += ['INTPTLAT', 'INTPTLON', 'LSADC', 'PARTFLAG', 'UGA']\n",
    "\n",
    "# for i in range(0, len(column_names)):    \n",
    "#     if (np.isnan(pandas.to_numeric(column_names[i], errors='coerce'))):\n",
    "#         geo_df = geo_df.rename(columns = {i: column_names[i]})\n",
    "#     else:\n",
    "#         geo_df = geo_df.rename(columns = {i: int(column_names[i])})\n",
    "\n",
    "geo_df.columns = column_names\n",
    "\n",
    "print('\\tTotal columns: {0:.0f}'.format(len(geo_df.columns)))\n",
    "print('\\tNamed columns: {0:.0f}'.format(len(column_names)))\n",
    "\n",
    "geo_df = geo_df.set_index('GEOID')\n",
    "\n",
    "\n",
    "# print('finding stuff...')\n",
    "# mycol = 'UGA'\n",
    "# showcolumns = []\n",
    "# showcolumns += ['SUMLEV', mycol]\n",
    "#geo_df[geo_df[mycol].notnull()][showcolumns]\n",
    "#print('done')\n",
    "\n",
    "geo_df.merge(sumlevel_df, how='left', on='SUMLEV')\n",
    "geo_df.set_index('SUMLEV')\n",
    "print('adding summary level descriptions...')\n",
    "geo_df = geo_df.reset_index().merge(sumlevel_df, how='left', on='SUMLEV').set_index('GEOID')\n",
    "geo_df = geo_df.rename(columns={'description': 'sumlev_description'})\n",
    "\n",
    "#geo_df\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('\\n')\n",
    "print('Read {0:,.0f} geographies in {1:.0f} minutes {2:.0f} seconds!'.format(len(geo_df), np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('counting by summary level...')\n",
    "count_df = pandas.DataFrame(data=None, columns=['sumlev_description', 'count', 'pop'], index=sumlevel_df['SUMLEV'].tolist())\n",
    "count_df.index.name = 'SUMLEV'\n",
    "count_df.loc[:, 'sumlev_description'] = sumlevel_df.set_index('SUMLEV')['description']\n",
    "count_df.loc[:, 'count'] = geo_df.groupby('SUMLEV').size()\n",
    "count_df.loc[:, 'pop'] = geo_df.groupby('SUMLEV')['POP100'].sum()\n",
    "#count_df\n",
    "nan_levels = count_df[count_df['count'].isnull()].index.tolist()\n",
    "\n",
    "htmlstr = ''\n",
    "htmlstr += '<table>'\n",
    "htmlstr += '<tr>'\n",
    "htmlstr += '<th>SUMLEVEL</th>'\n",
    "for thiscol in count_df.columns.tolist():    \n",
    "    htmlstr += '<th>{0:}</th>'.format(thiscol)\n",
    "htmlstr += '</tr>'\n",
    "\n",
    "for sumlev, thisrow in count_df.iterrows():\n",
    "    #if ('remainder' not in thisrow['sumlev_description'].lower()):\n",
    "    if (sumlev not in nan_levels):\n",
    "        htmlstr += '<tr>'    \n",
    "        htmlstr += '<td>{0:3d}</td><td>{1:}</td><td>{2:,.0f}</td><td>{3:,.0f}</td>'.format(sumlev, thisrow['sumlev_description'], thisrow['count'], thisrow['pop'])\n",
    "        htmlstr += '</tr>'\n",
    "htmlstr += '</table>'\n",
    "\n",
    "# print('No data for these columns: {0:}'.format(nan_levels))\n",
    "# display(HTML(htmlstr))\n",
    "\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('\\n')\n",
    "print('Documented {0:,.0f} geographies in {1:.1f} seconds!'.format(len(count_df), e-s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('getting tract data...')\n",
    "s = time.time()\n",
    "tract_df = geo_df[geo_df['SUMLEV'] == 140]\n",
    "tract_df = tract_df.assign(census_tract = tract_df['TRACT'].apply(lambda x: x/100))\n",
    "#tract_df[['SUMLEV', 'STATE', 'STUSAB', 'COUNTY', 'census_tract', 'BLKGRP', 'NAME']].sample(3)\n",
    "\n",
    "print('looking up state names from numbers...')\n",
    "state_codes_df = pandas.read_csv(extras_dir+'statecodes.csv')\n",
    "tract_df = tract_df.reset_index().merge(state_codes_df[['STATE', 'STATE_NAME']], how='left', on='STATE').set_index('GEOID')\n",
    "\n",
    "\n",
    "print('looking up county names from numbers...')\n",
    "county_names_df = pandas.read_excel(extras_dir+'all-geocodes-v2019.xlsx', header=4)\n",
    "county_names_df = county_names_df[county_names_df['Summary Level'] == 50]\n",
    "county_names_df = county_names_df.rename(columns={'State Code (FIPS)': 'STATE', 'County Code (FIPS)': 'COUNTY', 'Area Name (including legal/statistical area description)': 'COUNTY_NAME' })\n",
    "county_names_df = county_names_df.reset_index(drop=True)\n",
    "tract_df = tract_df.reset_index().merge(county_names_df[['STATE', 'COUNTY', 'COUNTY_NAME']], how='left', on=['STATE', 'COUNTY']).set_index('GEOID')\n",
    "\n",
    "print('adding empty column for new districts...')\n",
    "tract_df = tract_df.assign(new_district = np.nan)\n",
    "\n",
    "print('adding shapefiles...')\n",
    "gdf = geopandas.GeoDataFrame()\n",
    "for this_state in tract_df['STATE'].drop_duplicates().tolist():\n",
    "    print('\\tgetting shapefiles for {0:}...'.format(state_codes_df[state_codes_df['STATE'] == this_state]['STUSAB'].values[0]))\n",
    "    gdf_i = geopandas.read_file(shapefile_basedir+'TRACT/tl_2020_{0:02d}_tract.shp'.format(this_state))\n",
    "    print('\\t\\t{0:} CRS = {1:}'.format(this_state, gdf_i.crs))\n",
    "    gdf = pandas.concat((gdf, gdf_i), axis=0)\n",
    "gdf.loc[:, 'GEOID'] = gdf['GEOID'].apply(lambda x: '1400000US'+x)\n",
    "gdf = gdf.set_index('GEOID')\n",
    "tract_gdf = geopandas.GeoDataFrame(data=tract_df.join(gdf.geometry), crs=gdf.crs, geometry='geometry')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#state_codes_df\n",
    "#tract_df = tract_gdf.reset_index().merge(state_codes_df[['STATE', 'STATE_NAME']], how='left', on='STATE').set_index('GEOID')\n",
    "\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('\\n')\n",
    "print('Joined {0:,.0f} tracts to shapefiles in {1:.1f} seconds!'.format(len(tract_gdf), e-s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('getting block group data...')\n",
    "# s = time.time()\n",
    "# bg_df = geo_df[geo_df['SUMLEV'] == 150]\n",
    "# bg_df = bg_df.assign(census_tract = bg_df['TRACT'].apply(lambda x: x/100))\n",
    "# #bg_df[['SUMLEV', 'STATE', 'STUSAB', 'COUNTY', 'census_tract', 'BLKGRP', 'NAME']].sample(3)\n",
    "\n",
    "# print('looking up state names from numbers...')\n",
    "# state_codes_df = pandas.read_csv(extras_dir+'statecodes.csv')\n",
    "# bg_df = bg_df.reset_index().merge(state_codes_df[['STATE', 'STATE_NAME']], how='left', on='STATE').set_index('GEOID')\n",
    "\n",
    "\n",
    "# print('looking up county names from numbers...')\n",
    "# county_names_df = pandas.read_excel(extras_dir+'all-geocodes-v2019.xlsx', header=4)\n",
    "# county_names_df = county_names_df[county_names_df['Summary Level'] == 50]\n",
    "# county_names_df = county_names_df.rename(columns={'State Code (FIPS)': 'STATE', 'County Code (FIPS)': 'COUNTY', 'Area Name (including legal/statistical area description)': 'COUNTY_NAME' })\n",
    "# county_names_df = county_names_df.reset_index(drop=True)\n",
    "# bg_df = bg_df.reset_index().merge(county_names_df[['STATE', 'COUNTY', 'COUNTY_NAME']], how='left', on=['STATE', 'COUNTY']).set_index('GEOID')\n",
    "\n",
    "# print('adding empty column for new districts...')\n",
    "# bg_df = bg_df.assign(new_district = np.nan)\n",
    "\n",
    "# print('adding shapefiles...')\n",
    "# gdf = geopandas.GeoDataFrame()\n",
    "# for this_state in bg_df['STATE'].drop_duplicates().tolist():\n",
    "#     print('\\tgetting shapefiles for {0:}...'.format(state_codes_df[state_codes_df['STATE'] == this_state]['STUSAB'].values[0]))\n",
    "#     gdf_i = geopandas.read_file(shapefile_basedir+'BG/tl_2020_{0:02d}_bg.shp'.format(this_state))\n",
    "#     print('\\t\\t{0:} CRS = {1:}'.format(this_state, gdf_i.crs))\n",
    "#     gdf = pandas.concat((gdf, gdf_i), axis=0)\n",
    "# gdf.loc[:, 'GEOID'] = gdf['GEOID'].apply(lambda x: '1500000US'+x)\n",
    "# gdf = gdf.set_index('GEOID')\n",
    "# bg_gdf = geopandas.GeoDataFrame(data=bg_df.join(gdf.geometry), crs=gdf.crs, geometry='geometry')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #state_codes_df\n",
    "# #bg_df = bg_gdf.reset_index().merge(state_codes_df[['STATE', 'STATE_NAME']], how='left', on='STATE').set_index('GEOID')\n",
    "\n",
    "# e = time.time()\n",
    "# g += (e-s)\n",
    "# print('\\n')\n",
    "# print('Joined {0:,.0f} block groups to shapefiles in {1:.1f} seconds!'.format(len(bg_gdf), e-s))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "cd_df = geo_df[geo_df['SUMLEV'] == 500]\n",
    "cd_df = cd_df[cd_df['CD116'] != 'ZZ']\n",
    "cd_df.loc[:, 'CD116'] = pandas.to_numeric(cd_df['CD116'], errors='coerce')\n",
    "cd_df.loc[cd_df['CD116'] == 0, 'CD116'] = 1\n",
    "\n",
    "print('adding shapefiles...')\n",
    "gdf = geopandas.read_file(shapefile_basedir+'CD/tl_2020_us_cd116.shp')\n",
    "gdf.loc[:, 'GEOID'] = gdf['GEOID'].apply(lambda x: '5001600US'+x)\n",
    "gdf = gdf.set_index('GEOID')\n",
    "\n",
    "cd_gdf = geopandas.GeoDataFrame(data=cd_df.join(gdf.geometry), crs=gdf.crs, geometry='geometry')\n",
    "#cd_gdf\n",
    "\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('\\n')\n",
    "print('Joined {0:,.0f} congressional districts to shapefiles in {1:.1f} seconds!'.format(len(cd_gdf), e-s))\n",
    "#cd_gdf[['STATE', 'STUSAB']].drop_duplicates()\n",
    "#cd_gdf.plot()\n",
    "# print(cd_gdf.groupby('CD116')['POP100'].sum())\n",
    "# print('\\n')\n",
    "# print(cd_gdf.groupby('STUSAB')['POP100'].sum())\n",
    "# print('\\n')\n",
    "# print('{0:,.0f}'.format(cd_gdf['POP100'].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "\n",
    "\n",
    "state_numbers_include_list = cd_gdf['STATE'].drop_duplicates().tolist()\n",
    "state_numbers_include_list = ['{0:02d}'.format(x) for x in state_numbers_include_list]\n",
    "\n",
    "print('getting states...')\n",
    "state_gdf = geopandas.read_file(shapefile_basedir+'tl_2020_us_state.shp')\n",
    "state_gdf.loc[:, 'INTPTLON'] = pandas.to_numeric(state_gdf['INTPTLON'])\n",
    "state_gdf.loc[:, 'INTPTLAT'] = pandas.to_numeric(state_gdf['INTPTLAT'])\n",
    "state_gdf.loc[:, 'STATEFP'] = pandas.to_numeric(state_gdf['STATEFP'], errors='coerce')\n",
    "state_gdf = state_gdf[state_gdf['STATEFP'].isin(state_numbers_include_list)]\n",
    "\n",
    "print('getting counties...')\n",
    "county_gdf = geopandas.read_file(shapefile_basedir+'tl_2020_us_county.shp')\n",
    "county_gdf.loc[:, 'STATEFP'] = pandas.to_numeric(county_gdf['STATEFP'], errors='coerce')\n",
    "county_gdf.loc[:, 'INTPTLON'] = pandas.to_numeric(county_gdf['INTPTLON'])\n",
    "county_gdf.loc[:, 'INTPTLAT'] = pandas.to_numeric(county_gdf['INTPTLAT'])\n",
    "county_gdf = county_gdf[county_gdf['STATEFP'].isin(state_numbers_include_list)]\n",
    "\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('Got {0:,.0f} states and {1:,.0f} counties in {2:.1f} seconds!'.format(len(state_gdf), len(county_gdf), e-s))\n",
    "print('\\n')\n",
    "\n",
    "if (show_water):\n",
    "    print('getting water areas...')\n",
    "\n",
    "    waterfiles = [shapefile_basedir+'AREAWATER/'+x for x in os.listdir(shapefile_basedir+'AREAWATER/') if ((x[-4:] == '.shp') )]\n",
    "    state_numbers_include_list = cd_gdf['STATE'].drop_duplicates().tolist()\n",
    "    state_numbers_include_list = ['{0:02d}'.format(x) for x in state_numbers_include_list]\n",
    "\n",
    "    waterfiles = [x for x in waterfiles if x[89:91] in state_numbers_include_list]\n",
    "\n",
    "    water_gdf = geopandas.GeoDataFrame()\n",
    "    #state_numbers_include_list = list(set([pandas.to_numeric(x[89:91], errors='coerce') for x in waterfiles]))\n",
    "    #[x for x in waterfiles if ()]\n",
    "    #possible_state_list = state_codes_df[state_codes_df['STATE'] <= 56]['STATE'].tolist()\n",
    "    for i in range(0, len(waterfiles)):\n",
    "        if (np.mod(i, 50) == 0):\n",
    "            print('\\treading water file {0:,.0f} of {1:,.0f}...'.format(i, len(waterfiles)))\n",
    "        water_gdf_i = geopandas.read_file(waterfiles[i])\n",
    "        water_gdf_i = water_gdf_i[water_gdf_i['AWATER'] >= water_area_tol]\n",
    "        water_gdf = pandas.concat((water_gdf, water_gdf_i), axis=0)\n",
    "    e = time.time()\n",
    "    g += (e-s)\n",
    "\n",
    "    print('Got {0:,.0f} water areas in {1:.0f} minutes {2:.1f} seconds!'.format(len(water_gdf), np.floor((e-s)/60), (e-s)%60))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "s = time.time()\n",
    "print('getting CBSAs (metro areas)...')\n",
    "cbsa_gdf = geopandas.read_file(shapefile_basedir+'CBSA/tl_2020_us_cbsa.shp')\n",
    "cbsa_gdf.loc[:, 'INTPTLON'] = pandas.to_numeric(cbsa_gdf['INTPTLON'])\n",
    "cbsa_gdf.loc[:, 'INTPTLAT'] = pandas.to_numeric(cbsa_gdf['INTPTLAT'])\n",
    "\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('Got {0:,.0f} CBSAs in {1:.1f} seconds!'.format(len(cbsa_gdf), e-s))\n",
    "print('\\n')\n",
    "s = time.time()\n",
    "print('getting places...')\n",
    "placefiles = [shapefile_basedir+'PLACE/'+x for x in os.listdir(shapefile_basedir+'PLACE/') if ((x[-4:] == '.shp'))]\n",
    "placefiles = [x for x in placefiles if x[85:87] in state_numbers_include_list]\n",
    "\n",
    "place_gdf = geopandas.GeoDataFrame()\n",
    "\n",
    "for i in range(0, len(placefiles)):\n",
    "    if (np.mod(i, 5) == 0):\n",
    "        print('\\treading place file {0:,.0f} of {1:,.0f}...'.format(i, len(placefiles)))\n",
    "    place_gdf_i = geopandas.read_file(placefiles[i])\n",
    "    place_gdf = pandas.concat((place_gdf, place_gdf_i), axis=0)\n",
    "place_gdf.loc[:, 'INTPTLON'] = pandas.to_numeric(place_gdf['INTPTLON'])\n",
    "place_gdf.loc[:, 'INTPTLAT'] = pandas.to_numeric(place_gdf['INTPTLAT'])\n",
    "\n",
    "place_gdf.loc[:, 'GEOID'] = place_gdf['GEOID'].apply(lambda x: '1600000US'+x)\n",
    "place_gdf = place_gdf.set_index('GEOID')\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('Got {0:,.0f} places in {1:.1f} seconds!'.format(len(place_gdf), e-s))\n",
    "print('\\n')\n",
    "\n",
    "if (show_roads):\n",
    "    print('getting roads...')\n",
    "roads_gdf = geopandas.GeoDataFrame()\n",
    "roads_file_list = [shapefile_basedir+'ROADS/'+x for x in os.listdir(shapefile_basedir+'ROADS/') if ((x[-4:] == '.shp') and (x[8:10] in state_numbers_include_list))]# and ('_{0:02d}'.format()))]# and ('tl_2018_{0:02d}'.format(this_state_number) in x))]\n",
    "for i in range(0, len(roads_file_list)):\n",
    "    if ((np.mod(i,10) == 0) | (i == len(roads_file_list)-1)):\n",
    "        print('\\tReading road file {0:,.0f} of {1:,.0f}...'.format(i+1, len(roads_file_list)))\n",
    "    roads_gdf_i = geopandas.read_file(roads_file_list[i])\n",
    "    \n",
    "    roads_gdf = pandas.concat((roads_gdf, roads_gdf_i), axis=0, sort=False)\n",
    "roads_gdf = roads_gdf.set_index('LINEARID')\n",
    "e = time.time()\n",
    "g += (e-s)\n",
    "print('Got {0:,.0f} roads in {1:.0f} minutes {2:.1f} seconds!'.format(len(roads_gdf), np.floor((e-s)/60), (e-s)%60))\n",
    "#print('\\n')\n",
    "\n",
    "\n",
    "print('Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlimits = cd_gdf.geometry.apply(lambda x: (x.bounds[0], x.bounds[2])).values[0]\n",
    "ylimits = cd_gdf.geometry.apply(lambda x: (x.bounds[1], x.bounds[3])).values[0]\n",
    "\n",
    "xspan = xlimits[1] - xlimits[0]\n",
    "yspan = ylimits[1] - ylimits[0]\n",
    "aspect_ratio = xspan / yspan\n",
    "\n",
    "xbuffer = xspan * map_buffer_ratio\n",
    "ybuffer = yspan * map_buffer_ratio\n",
    "\n",
    "xlimits = cd_gdf.geometry.apply(lambda x: (x.bounds[0] - xbuffer, x.bounds[2] + xbuffer)).values[0]\n",
    "ylimits = cd_gdf.geometry.apply(lambda x: (x.bounds[1] - ybuffer, x.bounds[3] + ybuffer)).values[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(xspan*scale, yspan*scale))\n",
    "ax.set_aspect('equal')\n",
    "#thedistricts = [x for x in cd_gdf['CD116'].drop_duplicates().tolist()]\n",
    "\n",
    "thedistricts = list(set([int(x) for x in cd_gdf['CD116'].drop_duplicates().tolist()]))\n",
    "\n",
    "legend_list = []\n",
    "\n",
    "print('ploting congressional districts...')\n",
    "for thiscd in thedistricts:\n",
    "    print('Plotting district {0:.0f}...'.format(thiscd))\n",
    "    #cd_gdf[cd_gdf['CD116'] == thiscd].to_crs(epsg=theproj).plot(ax=ax, color=district_color_cycle[thiscd])\n",
    "    cd_gdf[cd_gdf['CD116'] == thiscd].plot(ax=ax, color=district_color_cycle[thiscd])\n",
    "    legend_list.append(mpatches.Patch(color=district_color_cycle[thiscd], label='District {0:,.0f}'.format(thiscd)))\n",
    "    \n",
    "    annotator = thiscd #parse_road_name(thisrow['FULLNAME'])\n",
    "    centerpoint = (cd_gdf[cd_gdf['CD116'] == thiscd]['INTPTLON'].values[0], cd_gdf[cd_gdf['CD116'] == thiscd]['INTPTLAT'].values[0])\n",
    "    ax.annotate(annotator, centerpoint, \n",
    "                color='black', backgroundcolor='white', ha='center', va='center', fontsize=2.25*scale)\n",
    "    \n",
    "print('ploting census tracts...')\n",
    "tract_gdf.plot(ax=ax, color='none', edgecolor='black', linewidth=0.0625*scale)\n",
    "\n",
    "if (show_water):\n",
    "    print('ploting water areas...')\n",
    "    water_gdf.plot(ax=ax, color='blue')\n",
    "    \n",
    "#state_gdf.to_crs(epsg=theproj).plot(ax=ax, color='none', edgecolor='black', lw=0.25*scale)\n",
    "state_gdf.plot(ax=ax, color='none', edgecolor='black', lw=0.25*scale)\n",
    "    \n",
    "ax.legend(handles=legend_list, fontsize=2.25*scale)\n",
    "\n",
    "if (len(list(these_states_dict.keys())) == 1):\n",
    "    plt.title('Current {0:} Congressional Districts (n = {1:.0f})'.format(\n",
    "        list(these_states_dict.keys())[0], \n",
    "        these_states_dict[list(these_states_dict.keys())[0]]['seats_old']\n",
    "    ), fontsize=3*scale)\n",
    "else:\n",
    "    plt.title('Current Congressional Districts', fontsize=3*scale)\n",
    "\n",
    "plt.xticks(fontsize=2*scale)\n",
    "plt.yticks(fontsize=2*scale)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# #fig.get_size_inches()\n",
    "#cd_gdf[cd_gdf['CD116'] == 'ZZ']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,)\n",
    "#cd_gdf[cd_gdf['CD116'] == 1]\n",
    "\n",
    "state_districts_average = cd_gdf['POP100'].sum() / len(cd_gdf)\n",
    "state_target = state_districts_average\n",
    "for i in range(1, these_states_dict[list(these_states_dict.keys())[0]]['seats_old']+1):\n",
    "    print('District {0:} (pop = {1:,.0f} ({2:.1%} of target, overshoot = {3:,.0f}))'.format(cd_gdf[cd_gdf['CD116'] == i]['BASENAME'].values[0], cd_gdf[cd_gdf['CD116'] == i]['POP100'].sum(), cd_gdf[cd_gdf['CD116'] == i]['POP100'].sum() / state_districts_average, cd_gdf[cd_gdf['CD116'] == i]['POP100'].sum() - state_districts_average))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tract_gdf.loc[:, 'new_district'] = np.nan\n",
    "\n",
    "county_mapper_df = pandas.DataFrame(data=[\n",
    "    ['Allegany County',6],\n",
    "    ['Anne Arundel County',4],\n",
    "    ['Baltimore County',2],\n",
    "    ['Baltimore city',7],\n",
    "    ['Calvert County',5],\n",
    "    ['Caroline County',1],\n",
    "    ['Carroll County',3],\n",
    "    ['Cecil County',1],\n",
    "    ['Charles County',5],\n",
    "    ['Dorchester County',1],\n",
    "    ['Frederick County',6],\n",
    "    ['Garrett County',6],\n",
    "    ['Harford County',1],\n",
    "    ['Howard County',3],\n",
    "    ['Kent County',1],\n",
    "    ['Montgomery County',8],\n",
    "    [\"Prince George's County\",4],\n",
    "    [\"Queen Anne's County\",1],\n",
    "    ['Somerset County',1],\n",
    "    [\"St. Mary's County\",5],\n",
    "    ['Talbot County',1],\n",
    "    ['Washington County',6],\n",
    "    ['Wicomico County',1],\n",
    "    ['Worcester County',1]\n",
    "], columns=['COUNTY_NAME', 'new_district_by_county'])\n",
    "\n",
    "place_mapper_df = pandas.DataFrame(data=[\n",
    "    ['Towson',7],\n",
    "    ['Pikesville',7],\n",
    "    ['Parkville',7],\n",
    "    ['Baltimore Highlands',7],\n",
    "    ['Arbutus',7],\n",
    "    ['Lansdowne',7],\n",
    "    ['Brooklyn Park',7],\n",
    "    ['Damascus',6],\n",
    "    ['Germantown',6],\n",
    "    ['Clarksburg',6],\n",
    "    ['Gaithersburg',6],\n",
    "    ['Laurel',3],\n",
    "    ['West Laurel',3],\n",
    "    ['South Laurel',3],\n",
    "    ['Maryland City',3], \n",
    "    ['Ilchester',2],\n",
    "    ['Elkridge',2],\n",
    "    ['Linthicum',2], \n",
    "    ['Ferndale',2],\n",
    "    ['Glen Burnie',2],\n",
    "    ['Jessup',3],\n",
    "    ['Cloverly',3],\n",
    "    ['Colesville',3],\n",
    "    ['Bladensburg',4],\n",
    "    ['Hyattsville',4]\n",
    "], columns=['NAME', 'new_district_by_place'])\n",
    "\n",
    "tract_gdf.loc[:, 'new_district'] = tract_df.reset_index().merge(county_mapper_df, how='left', on='COUNTY_NAME').set_index('GEOID')['new_district_by_county']\n",
    "\n",
    "\n",
    "tract_gdf.loc[(tract_gdf['COUNTY_NAME'] == 'Baltimore County') & (tract_gdf['INTPTLAT'] >= 39.525), 'new_district'] = 1\n",
    "tract_gdf.loc[(tract_gdf['COUNTY_NAME'] == 'Montgomery County') & (tract_gdf['INTPTLON'] <= -77.225), 'new_district'] = 6\n",
    "tract_gdf.loc[(tract_gdf['COUNTY_NAME'] == 'Montgomery County') & ((tract_gdf['INTPTLON'] >= -77.225) & (tract_gdf['INTPTLAT'] >= 39.125)), 'new_district'] = 3\n",
    "tract_gdf.loc[(tract_gdf['COUNTY_NAME'] == \"Prince George's County\") & (tract_gdf['INTPTLAT'] <= 38.9), 'new_district'] = 5\n",
    "tract_gdf.loc[(tract_gdf['COUNTY_NAME'] == \"Prince George's County\") & ((tract_gdf['INTPTLAT'] >= 38.9) & (tract_gdf['INTPTLON'] <= -76.92)), 'new_district'] = 8\n",
    "#tract_gdf.loc[(tract_gdf['COUNTY_NAME'] == 'Anne Arundel County') & (tract_gdf['INTPTLAT'] >= 39.125), 'new_district'] = 2\n",
    "\n",
    "place_mapper_gdf = geopandas.GeoDataFrame(place_mapper_df.merge(place_gdf.reset_index(), how='left', on='NAME')[['GEOID', 'NAME', 'new_district_by_place', 'geometry']].set_index('GEOID'))\n",
    "for i in range(1, these_states_dict[list(these_states_dict.keys())[0]]['seats_new']+1):\n",
    "    #tract_gdf.loc[(tract_gdf['new_district'].isnull()) & (tract_gdf.geometry.within(unary_union(place_mapper_gdf[place_mapper_gdf['new_district_by_place'] == i].geometry.tolist()))), 'new_district'] = i\n",
    "    tract_gdf.loc[(tract_gdf.geometry.within(unary_union(place_mapper_gdf[place_mapper_gdf['new_district_by_place'] == i].geometry.tolist()))), 'new_district'] = i\n",
    "\n",
    "    \n",
    "tract_gdf.loc[['1400000US24005490400', '1400000US24003750201', '1400000US24003750300'], 'new_district'] = 7\n",
    "\n",
    "tract_gdf.loc[['1400000US24005408200'], 'new_district'] = 1    # N Baltimore County\n",
    "tract_gdf.loc[['1400000US24005404600'], 'new_district'] = 3   # N Baltimore County\n",
    "tract_gdf.loc[['1400000US24005410200', '1400000US24005411201'], 'new_district'] = 1  # N Baltimore County\n",
    "tract_gdf.loc[['1400000US24005402201', '1400000US24005404800', '1400000US24005402202', '1400000US24027602700'], 'new_district'] = 3 # W Baltimore County\n",
    "tract_gdf.loc[['1400000US24005411101', '1400000US24005411102', '1400000US24005411202', '1400000US24005451702', '1400000US24005451801', '1400000US24005411302'], 'new_district'] = 1 # NE Baltimore County\n",
    "\n",
    "\n",
    "\n",
    "tract_gdf.loc[['1400000US24003750900', '1400000US24003751200', '1400000US24003980000'], 'new_district'] = 2  # Glen Burnie / BWI\n",
    "tract_gdf.loc[['1400000US24027601104', '1400000US24027601203', '1400000US24027602700'], 'new_district'] = 2  # Elkridge / Ilchester\n",
    "\n",
    "tract_gdf.loc[['1400000US24031701409', '1400000US24031701414', '1400000US24031701415', '1400000US24031701417', '1400000US24031701418', '1400000US24031701422', '1400000US24031701423'], 'new_district'] = 3  # near Laurel\n",
    "tract_gdf.loc[['1400000US24031701426', '1400000US24031701427', '1400000US24033800105', '1400000US24033800106', '1400000US24033800203', '1400000US24033800212', '1400000US24033800213', '1400000US24033807407', '1400000US24031701424'], 'new_district'] = 3  # near Laurel\n",
    "\n",
    "\n",
    "tract_gdf.loc[['1400000US24031700204', '1400000US24031700209', '1400000US24031700315', '1400000US24031700724', '1400000US24031700829', '1400000US24031700836', '1400000US24031700733', '1400000US24031700810', '1400000US24031700813'], 'new_district'] = 6\n",
    "\n",
    "\n",
    "tract_gdf.loc[['1400000US24031700723', '1400000US24031700724', '1400000US24031700725', '1400000US24031700726', '1400000US24031700727', '1400000US24031700731'], 'new_district'] = 8\n",
    "\n",
    "\n",
    "tract_gdf.loc[['1400000US24003740106', '1400000US24003751500'], 'new_district'] = 3  #  NW Anne Arundel County\n",
    "tract_gdf.loc[['1400000US24003740603'], 'new_district'] = 3  #  W Anne Arundel County\n",
    "tract_gdf.loc[['1400000US24033807408', '1400000US24033800410', '1400000US24033800411'], 'new_district'] = 3  #  W Anne Arundel County\n",
    "\n",
    "\n",
    "tract_gdf.loc[['1400000US24033806900', '1400000US24033807404'], 'new_district'] = 8  #  N of College Park\n",
    "    \n",
    "tract_gdf.loc[['1400000US24033803900', '1400000US24033804002', '1400000US24033804300', '1400000US24033804400'], 'new_district'] = 4  #  Bladensburg /  Hyattsville\n",
    "tract_gdf.loc[['1400000US24033804600', '1400000US24033804700', '1400000US24033804801', '1400000US24033804802'], 'new_district'] = 4  #  Bladensburg /  Hyattsville\n",
    "tract_gdf.loc[['1400000US24033806501', '1400000US24033807102', '1400000US24033807500'], 'new_district'] = 4  #  Bladensburg /  Hyattsville\n",
    "\n",
    "# for i in range(1, these_states_dict[list(these_states_dict.keys())[0]]['seats_new']+1):\n",
    "#     print(place_mapper_df[place_mapper_df['new_district_by_place'] == i])\n",
    "#place_mapper_df\n",
    "\n",
    "#place_mapper_df.merge(place_gdf.reset_index(), how='left', on='NAME').set_index('GEOID').geometry\n",
    "\n",
    "\n",
    "#tract_gdf[tract_gdf.geometry.within(unary_union(place_mapper_gdf[place_mapper_gdf['new_district_by_place'] == 7].geometry.tolist()))]['new_district']\n",
    "#tract_gdf.groupby('new_district')['POP100'].sum()\n",
    "#fig, ax = plt.subplots(1,1)\n",
    "#tract_gdf.plot(ax=ax, color='none', edgecolor='black')\n",
    "\n",
    "print('\\n')\n",
    "for i in range(1, these_states_dict[list(these_states_dict.keys())[0]]['seats_new']+1):\n",
    "    if (tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() > 0):\n",
    "        #if (np.abs(tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() - state_target) >= 1000):\n",
    "        print('District {0:}: n = {1:,.0f} ({2:.1%} of target; overshot = {3:,.0f})'.format(i, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum(), tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum()/state_target, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() - state_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_water = True\n",
    "show_roads = False\n",
    "label_tracts = False\n",
    "label_places = False\n",
    "\n",
    "the_label_size = 12\n",
    "the_annotation_size = 12\n",
    "the_line_width = .25\n",
    "the_line_width_wide = 4\n",
    "the_legend_size = 12\n",
    "the_title_size = 16\n",
    "\n",
    "maybe_other_tracts = []\n",
    "\n",
    "places_to_show = []\n",
    "#places_to_show += maybe_other_places\n",
    "\n",
    "place_color = 'green'\n",
    "\n",
    "bounds_counties = [\"Prince George's\"]\n",
    "\n",
    "xlimits = state_gdf.geometry.apply(lambda x: (x.bounds[0], x.bounds[2])).values[0]\n",
    "ylimits = state_gdf.geometry.apply(lambda x: (x.bounds[1], x.bounds[3])).values[0]\n",
    "\n",
    "# xlimits = [unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[0], unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[2]]\n",
    "# ylimits = [unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[1], unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[3]]\n",
    "\n",
    "\n",
    "# # # Prince George's DC suburbs\n",
    "# xlimits = [-77.03,-76.83]\n",
    "# ylimits = [38.9,39.13]\n",
    "\n",
    "xspan = xlimits[1] - xlimits[0]\n",
    "yspan = ylimits[1] - ylimits[0]\n",
    "aspect_ratio = xspan / yspan\n",
    "\n",
    "xbuffer = xspan * map_buffer_ratio\n",
    "ybuffer = yspan * map_buffer_ratio\n",
    "\n",
    "xlimits = [xlimits[0] - xbuffer, xlimits[1] + xbuffer] #cd_gdf.geometry.apply(lambda x: (x.bounds[0] - xbuffer, x.bounds[2] + xbuffer)).values[0]\n",
    "ylimits = [ylimits[0] - ybuffer, ylimits[1] + ybuffer] \n",
    "\n",
    "print('xspan = {0:,.2f} degrees'.format(xspan))\n",
    "print('aspect_ratio  = {0:,.2f}:1'.format(aspect_ratio))\n",
    "print('\\n')\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(xspan*scale, yspan*scale))\n",
    "fig, ax = plt.subplots(1,1,figsize=(24, 24/aspect_ratio))\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# print('plotting CBSAs...')\n",
    "# cbsa_gdf[\n",
    "#     ((cbsa_gdf['INTPTLON'] >= xlimits[0]) & (cbsa_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#     & ((cbsa_gdf['INTPTLAT'] >= ylimits[0]) & (cbsa_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "# ].plot(ax=ax, color='none', edgecolor='yellow')\n",
    "\n",
    "\n",
    "print('plotting tracts...')\n",
    "\n",
    "# base layer\n",
    "print('\\tbase layer...')\n",
    "legend_list = []\n",
    "for i in range(1,9):\n",
    "    if (tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() > 0):\n",
    "        #print(i, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum())\n",
    "        tract_gdf[(tract_gdf['new_district'] == i)].plot(ax=ax, color=district_color_cycle[i], edgecolor='black', linewidth=the_line_width)#, alpha=0.25)        \n",
    "        legend_list.append(mpatches.Patch(color=district_color_cycle[i], label='District {0:,.0f}'.format(i)))\n",
    "\n",
    "        \n",
    "if (len(maybe_other_tracts) > 0):\n",
    "#    tract_gdf[(tract_gdf['new_district'].isnull()) & (tract_gdf['census_tract'].apply(lambda x: x not in maybe_other_tracts))].plot(ax=ax, color='none', edgecolor='black', lw=the_line_width)\n",
    "    tract_gdf[(tract_gdf['census_tract'].apply(lambda x: x not in maybe_other_tracts))].plot(ax=ax, color='none', edgecolor='black', lw=the_line_width)\n",
    "    tract_gdf[(tract_gdf['census_tract'].isin(maybe_other_tracts))].plot(ax=ax, color='none', edgecolor='orange', lw=the_line_width_wide, linestyle='solid')\n",
    "else:\n",
    "    tract_gdf[(tract_gdf['new_district'].isnull())].plot(ax=ax, color='none', edgecolor='gray', lw=the_line_width)\n",
    "\n",
    "\n",
    "if (label_tracts):\n",
    "    print('labeling tracts...')\n",
    "    if (len(maybe_other_tracts) > 0):\n",
    "        print('maybe', len(maybe_other_tracts))\n",
    "        for ix, thisrow in tract_gdf[\n",
    "            ((tract_gdf['INTPTLON'] >= xlimits[0]) & (tract_gdf['INTPTLON'] <= xlimits[1])) & ((tract_gdf['INTPTLAT'] >= ylimits[0]) & (tract_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "            & (tract_gdf['census_tract'].isin(maybe_other_tracts))\n",
    "        ].sort_values(by='census_tract').iterrows():\n",
    "            print('census tract {0:}: ix = {1:}'.format(thisrow['census_tract'], ix))\n",
    "            annotator = '{0:}\\n{1:,.0f}'.format(thisrow['census_tract'], geo_df.loc[ix]['POP100'])\n",
    "            centerpoint = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "            ax.annotate(annotator, centerpoint, \n",
    "                        color='black', backgroundcolor='white', ha='center', va='center', \n",
    "                        fontsize=the_annotation_size)\n",
    "    else:\n",
    "        for ix, thisrow in tract_gdf[\n",
    "            (((tract_gdf['INTPTLON'] >= xlimits[0]) & (tract_gdf['INTPTLON'] <= xlimits[1])) & ((tract_gdf['INTPTLAT'] >= ylimits[0]) & (tract_gdf['INTPTLAT'] <= ylimits[1])))\n",
    "#            & (tract_gdf['new_district'].isnull())\n",
    "#            & (tract_gdf['new_district'] == 8)\n",
    "#            & (tract_gdf['INTPTLAT'] >= 39.05)\n",
    "#             & (\n",
    "#                 ((tract_gdf['INTPTLAT'] >= 39.37) & (tract_gdf['new_district'] == 2))\n",
    "#                 | ((tract_gdf['INTPTLON'] <=  -76.64) & (tract_gdf['new_district'] == 1))\n",
    "#               )\n",
    "        ].sort_values(by='census_tract').iterrows():\n",
    "            print('{0:}:\\t{1:}'.format(thisrow['census_tract'], ix))\n",
    "            annotator = '{0:}\\n{1:,.0f}'.format(thisrow['census_tract'], geo_df.loc[ix]['POP100'])\n",
    "            centerpoint = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "            ax.annotate(annotator, centerpoint, \n",
    "                        color='gray', backgroundcolor='white', ha='center', va='center', \n",
    "                        fontsize=the_annotation_size)\n",
    "\n",
    "\n",
    "# print('plotting places...')\n",
    "# if (len(places_to_show) > 0):\n",
    "#     place_gdf[\n",
    "#         ((place_gdf['INTPTLON'] >= xlimits[0]) & (place_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#         & ((place_gdf['INTPTLAT'] >= ylimits[0]) & (place_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "#         & (place_gdf['NAME'].isin(places_to_show))\n",
    "#     ].plot(ax=ax, edgecolor='red', lw=the_line_width_wide, color='none', linestyle='solid')\n",
    "# else:\n",
    "#     place_gdf[\n",
    "#         ((place_gdf['INTPTLON'] >= xlimits[0]) & (place_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#         & ((place_gdf['INTPTLAT'] >= ylimits[0]) & (place_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "#     ].plot(ax=ax, edgecolor='red', lw=the_line_width_wide, color='none')\n",
    "# if (label_places):\n",
    "#     if (len(places_to_show) > 0):\n",
    "#         print('\\tlabeing chosen places...')\n",
    "#         for ix, thisrow in place_gdf[\n",
    "#             ((place_gdf['INTPTLON'] >= xlimits[0]) & (place_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#             & ((place_gdf['INTPTLAT'] >= ylimits[0]) & (place_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "#             & (place_gdf['NAME'].isin(places_to_show))\n",
    "#         ].iterrows():\n",
    "#             annotator = '{0:}\\n{1:,.0f}'.format(thisrow['NAME'].replace('-','-\\n').replace(' ','\\n').upper(), geo_df.loc[ix]['POP100'])\n",
    "#             centerpoint = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "#             ax.annotate(annotator, centerpoint, \n",
    "#                         color='red', backgroundcolor='white', ha='center', va='center', \n",
    "#                         fontsize=the_annotation_size)\n",
    "#     else:\n",
    "#         print('\\tlabeing all places on map...')\n",
    "#         for ix, thisrow in place_gdf[\n",
    "#             ((place_gdf['INTPTLON'] >= xlimits[0]) & (place_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#             & ((place_gdf['INTPTLAT'] >= ylimits[0]) & (place_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "#         ].iterrows():\n",
    "#             annotator = '{0:}\\n{1:,.0f}'.format(thisrow['NAME'].replace('-','-\\n').replace(' ','\\n').upper(), geo_df.loc[ix]['POP100'])\n",
    "#             centerpoint = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "#             ax.annotate(annotator, centerpoint, \n",
    "#                         color='red', backgroundcolor='white', ha='center', va='center', \n",
    "#                         fontsize=the_annotation_size)\n",
    "\n",
    "if (show_water):\n",
    "    print('plotting water areas...')\n",
    "    water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "    \n",
    "if (show_roads):\n",
    "    print('plotting roads...')\n",
    "    print('\\tsmall...')\n",
    "    roads_gdf[~roads_gdf['RTTYP'].isin(['I','U','S','C'])].plot(ax=ax, color='black', linewidth=0.1)\n",
    "    print('\\tlarge...')\n",
    "    roads_gdf[roads_gdf['RTTYP'] == 'C'].plot(ax=ax, color='black', linewidth=0.25) \n",
    "    roads_gdf[roads_gdf['RTTYP'] == 'S'].plot(ax=ax, color='black', linewidth=0.5) \n",
    "    roads_gdf[roads_gdf['RTTYP'] == 'U'].plot(ax=ax, color='black', linewidth=0.75)     \n",
    "    roads_gdf[roads_gdf['RTTYP'] == 'I'].plot(ax=ax, color='black', linewidth=1) \n",
    "plt.xlim(xlimits)\n",
    "plt.ylim(ylimits)\n",
    "\n",
    "plt.xticks(fontsize=the_label_size)\n",
    "plt.yticks(fontsize=the_label_size)\n",
    "\n",
    "ax.legend(handles=legend_list, fontsize=the_legend_size)\n",
    "\n",
    "if (len(list(these_states_dict.keys())) == 1):\n",
    "    plt.title('New {0:} Congressional Districts (n = {1:.0f})'.format(\n",
    "        list(these_states_dict.keys())[0], \n",
    "        these_states_dict[list(these_states_dict.keys())[0]]['seats_new']\n",
    "    ), fontsize=the_title_size)\n",
    "else:    \n",
    "    plt.title('New Congressional Districts', fontsize=the_title_size)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print('\\n')\n",
    "for i in range(1, these_states_dict[list(these_states_dict.keys())[0]]['seats_new']+1):\n",
    "    if (tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() > 0):\n",
    "        #if (np.abs(tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() - state_target) >= 1000):\n",
    "        print('District {0:}: n = {1:,.0f} ({2:.1%} of target; overshot = {3:,.0f})'.format(i, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum(), tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum()/state_target, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() - state_target))\n",
    "\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_district_shapes_gdf = geopandas.GeoDataFrame(data=None, columns=['new_district', 'geometry'], crs=tract_gdf.crs, geometry='geometry').set_index('new_district')\n",
    "for i in range(1, these_states_dict[list(these_states_dict.keys())[0]]['seats_new']+1):\n",
    "    print('merging tract shapes get district {0:,.0f} boundaries...'.format(i))\n",
    "    new_district_shapes_gdf.loc[i, 'geometry'] = unary_union(tract_gdf[tract_gdf['new_district'] == i].geometry.tolist())    \n",
    "#new_district_shapes_gdf = new_district_shapes_gdf.reset_index()\n",
    "    \n",
    "xlimits = cd_gdf.geometry.apply(lambda x: (x.bounds[0], x.bounds[2])).values[0]\n",
    "ylimits = cd_gdf.geometry.apply(lambda x: (x.bounds[1], x.bounds[3])).values[0]\n",
    "\n",
    "xspan = xlimits[1] - xlimits[0]\n",
    "yspan = ylimits[1] - ylimits[0]\n",
    "aspect_ratio = xspan / yspan\n",
    "\n",
    "xbuffer = xspan * map_buffer_ratio\n",
    "ybuffer = yspan * map_buffer_ratio\n",
    "\n",
    "xlimits = cd_gdf.geometry.apply(lambda x: (x.bounds[0] - xbuffer, x.bounds[2] + xbuffer)).values[0]\n",
    "ylimits = cd_gdf.geometry.apply(lambda x: (x.bounds[1] - ybuffer, x.bounds[3] + ybuffer)).values[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(xspan*scale, yspan*scale))\n",
    "ax.set_aspect('equal')\n",
    "#thedistricts = [x for x in cd_gdf['CD116'].drop_duplicates().tolist()]\n",
    "\n",
    "thedistricts = list(set([int(x) for x in cd_gdf['CD116'].drop_duplicates().tolist()]))\n",
    "\n",
    "legend_list = []\n",
    "\n",
    "print('ploting congressional districts...')\n",
    "for thiscd in thedistricts:\n",
    "    print('Plotting district {0:.0f}...'.format(thiscd))\n",
    "    new_district_shapes_gdf[new_district_shapes_gdf.index == thiscd].plot(ax=ax, color=district_color_cycle[thiscd])\n",
    "    #cd_gdf[cd_gdf['CD116'] == thiscd].to_crs(epsg=theproj).plot(ax=ax, color=district_color_cycle[thiscd])\n",
    "    #cd_gdf[cd_gdf['CD116'] == thiscd].plot(ax=ax, color=district_color_cycle[thiscd])\n",
    "    legend_list.append(mpatches.Patch(color=district_color_cycle[thiscd], label='District {0:,.0f}'.format(thiscd)))\n",
    "    \n",
    "    \n",
    "    annotator = thiscd #parse_road_name(thisrow['FULLNAME'])\n",
    "    centerpoint = (unary_union(new_district_shapes_gdf[new_district_shapes_gdf.index == thiscd].geometry.tolist()).centroid.x, unary_union(new_district_shapes_gdf[new_district_shapes_gdf.index == thiscd].geometry.tolist()).centroid.y)\n",
    "    #centerpoint = (new_district_shapes_gdf[new_district_shapes_gdf.index == thiscd]['INTPTLON'].values[0], cd_gdf[cd_gdf['CD116'] == thiscd]['INTPTLAT'].values[0])\n",
    "    ax.annotate(annotator, centerpoint, \n",
    "                color='black', backgroundcolor='white', ha='center', va='center', fontsize=2.25*scale)\n",
    "    \n",
    "print('ploting census tracts...')\n",
    "tract_gdf.plot(ax=ax, color='none', edgecolor='black', linewidth=0.0625*scale)\n",
    "\n",
    "if (show_water):\n",
    "    print('ploting water areas...')\n",
    "    water_gdf.plot(ax=ax, color='blue')\n",
    "    \n",
    "#state_gdf.to_crs(epsg=theproj).plot(ax=ax, color='none', edgecolor='black', lw=0.25*scale)\n",
    "state_gdf.plot(ax=ax, color='none', edgecolor='black', lw=0.25*scale)\n",
    "    \n",
    "ax.legend(handles=legend_list, fontsize=2.25*scale)\n",
    "\n",
    "if (len(list(these_states_dict.keys())) == 1):\n",
    "    plt.title('Current {0:} Congressional Districts (n = {1:.0f})'.format(\n",
    "        list(these_states_dict.keys())[0], \n",
    "        these_states_dict[list(these_states_dict.keys())[0]]['seats_old']\n",
    "    ), fontsize=3*scale)\n",
    "else:\n",
    "    plt.title('Current Congressional Districts', fontsize=3*scale)\n",
    "\n",
    "plt.xticks(fontsize=2*scale)\n",
    "plt.yticks(fontsize=2*scale)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# #fig.get_size_inches()\n",
    "#cd_gdf[cd_gdf['CD116'] == 'ZZ']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_gdf['new_district'].to_csv(script_dir+'maryland.csv')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #district_7_remove_tracts = [4037.02]\n",
    "# print(district_7_remove_tracts)\n",
    "# tract_gdf.loc[tract_gdf['census_tract'][tract_gdf['census_tract'].isin(district_7_remove_tracts)].index.tolist(), 'new_district'] = np.nan\n",
    "# tract_gdf.loc[tract_gdf['census_tract'][tract_gdf['census_tract'].isin(district_7_remove_tracts)].index.tolist()]\n",
    "#tract_gdf['COUNTY_NAME'].apply(lambda x: '/'+x+'/').drop_duplicates()\n",
    "\n",
    "#place_gdf.join(geo_df[geo_df['SUMLEV'] == 160]['POP100'])[['NAME', 'POP100']].sort_values(by='POP100', ascending=False)[0:40]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # district_1_counties = ['Caroline', 'Cecil', 'Dorchester', 'Kent', \"Queen Anne's\", 'Somerset', 'Talbot', 'Wicomico', 'Worcester']\n",
    "# # district_5_counties = ['Calvert', 'Charles', \"St. Mary's\"]\n",
    "# # district_6_counties = ['Allegany', 'Garrett', 'Washington']\n",
    "\n",
    "# # # 1025       Anne Arundel\n",
    "# # # 183           Baltimore\n",
    "# # # 655           Baltimore\n",
    "# # #874             Calvert\n",
    "# # #2852           Caroline\n",
    "# # 816             Carroll\n",
    "# # #336               Cecil\n",
    "# # #2488            Charles\n",
    "# # #908          Dorchester\n",
    "# # 1050          Frederick\n",
    "# # #1439            Garrett\n",
    "# # 1985            Harford\n",
    "# # #1392             Howard\n",
    "# # #2064               Kent\n",
    "# # 1474         Montgomery\n",
    "# # 1361    Prince George's\n",
    "# # #1480       Queen Anne's\n",
    "# # 1963           Somerset\n",
    "# # #2003         St. Mary's\n",
    "# # #1620             Talbot\n",
    "# # 2742         Washington\n",
    "# # #1729           Wicomico\n",
    "# # #130           Worcester\n",
    "# print(district_1_counties)\n",
    "# tract_gdf[(tract_gdf['COUNTY_NAME'].isin(district_1_counties))]# & (tract_gdf['new_district'].isnull())]\n",
    "# tract_gdf['COUNTY_NAME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(xlimits)\n",
    "# print(ylimits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_water = False\n",
    "# label_tracts = True\n",
    "# label_places = False\n",
    "# places_to_label = ['Towson'] #['Germantown', 'Silver Spring', 'Bethesda', 'Annapolis']\n",
    "\n",
    "\n",
    "# the_label_size = 12\n",
    "# the_annotation_size = 9\n",
    "# the_line_width = 0.25\n",
    "# the_line_width_wide = 0.75\n",
    "# the_legend_size = 12\n",
    "# the_title_size = 16\n",
    "# place_color = 'green'\n",
    "\n",
    "\n",
    "\n",
    "# bounds_counties = ['Baltimore']#['Montgomery', 'Anne Arundel', \"Prince George's\"]\n",
    "\n",
    "# # xlimits = state_gdf.geometry.apply(lambda x: (x.bounds[0], x.bounds[2])).values[0]\n",
    "# # ylimits = state_gdf.geometry.apply(lambda x: (x.bounds[1], x.bounds[3])).values[0]\n",
    "\n",
    "# # xlimits = [unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[0], unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[2]]\n",
    "# # ylimits = [unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[1], unary_union(county_gdf[county_gdf['NAME'].isin(bounds_counties)].geometry.tolist()).bounds[3]]\n",
    "\n",
    "# xlimits = [-76.7,-76.55]\n",
    "# ylimits = [39.37, 39.45]\n",
    "\n",
    "# xspan = xlimits[1] - xlimits[0]\n",
    "# yspan = ylimits[1] - ylimits[0]\n",
    "# aspect_ratio = xspan / yspan\n",
    "\n",
    "# xbuffer = xspan * map_buffer_ratio\n",
    "# ybuffer = yspan * map_buffer_ratio\n",
    "\n",
    "# xlimits = [xlimits[0] - xbuffer, xlimits[1] + xbuffer] #cd_gdf.geometry.apply(lambda x: (x.bounds[0] - xbuffer, x.bounds[2] + xbuffer)).values[0]\n",
    "# ylimits = [ylimits[0] - ybuffer, ylimits[1] + ybuffer] \n",
    "\n",
    "# print('xspan = {0:,.2f} degrees'.format(xspan))\n",
    "# print('aspect_ratio  = {0:,.2f}:1'.format(aspect_ratio))\n",
    "# print('\\n')\n",
    "\n",
    "# # fig, ax = plt.subplots(1,1, figsize=(xspan*scale, yspan*scale))\n",
    "# fig, ax = plt.subplots(1,1,figsize=(24, 24/aspect_ratio))\n",
    "# ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "\n",
    "# # print('plotting CBSAs...')\n",
    "# # cbsa_gdf[\n",
    "# #     ((cbsa_gdf['INTPTLON'] >= xlimits[0]) & (cbsa_gdf['INTPTLON'] <= xlimits[1]))\n",
    "# #     & ((cbsa_gdf['INTPTLAT'] >= ylimits[0]) & (cbsa_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "# # ].plot(ax=ax, color='none', edgecolor='yellow')\n",
    "\n",
    "# print('plotting places...')\n",
    "# place_gdf[\n",
    "#     ((place_gdf['INTPTLON'] >= xlimits[0]) & (place_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#     & ((place_gdf['INTPTLAT'] >= ylimits[0]) & (place_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "# ].plot(ax=ax, edgecolor='red', lw=the_line_width_wide, color='none')#place_color, alpha=0.1)\n",
    "\n",
    "# if (label_places):\n",
    "#     if (len(places_to_label) == 0):\n",
    "#         print('\\tlabeing all places on map...')\n",
    "#         for ix, thisrow in place_gdf[\n",
    "#             ((place_gdf['INTPTLON'] >= xlimits[0]) & (place_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#             & ((place_gdf['INTPTLAT'] >= ylimits[0]) & (place_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "#         ].iterrows():\n",
    "#             annotator = '{0:}\\n{1:,.0f}'.format(thisrow['NAME'].replace('-','-\\n').replace(' ','\\n'), geo_df.loc[ix]['POP100'])\n",
    "#             centerpoint = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "#             ax.annotate(annotator, centerpoint, \n",
    "#                         color='black', backgroundcolor='white', ha='center', va='center', \n",
    "#                         fontsize=the_annotation_size)\n",
    "#     else:\n",
    "#         print('\\tlabeing chosen places...')\n",
    "#         for ix, thisrow in place_gdf[\n",
    "#             ((place_gdf['INTPTLON'] >= xlimits[0]) & (place_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#             & ((place_gdf['INTPTLAT'] >= ylimits[0]) & (place_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "#             & (place_gdf['NAME'].isin(places_to_label))\n",
    "#         ].iterrows():\n",
    "#             annotator = '{0:}\\n{1:,.0f}'.format(thisrow['NAME'].replace('-','-\\n').replace(' ','\\n'), geo_df.loc[ix]['POP100'])\n",
    "#             centerpoint = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "#             ax.annotate(annotator, centerpoint, \n",
    "#                         color='black', backgroundcolor='white', ha='center', va='center', \n",
    "#                         fontsize=the_annotation_size)\n",
    "\n",
    "# # print('plotting states...')\n",
    "# # state_gdf[\n",
    "# #     ((state_gdf['INTPTLON'] >= xlimits[0]) & (state_gdf['INTPTLON'] <= xlimits[1]))\n",
    "# #     & ((state_gdf['INTPTLAT'] >= ylimits[0]) & (state_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "# # ].plot(ax=ax, color='none', edgecolor='black', lw=the_line_width)\n",
    "\n",
    "# # print('plotting counties...')\n",
    "# # county_gdf[\n",
    "# #     ((county_gdf['INTPTLON'] >= xlimits[0]) & (county_gdf['INTPTLON'] <= xlimits[1]))\n",
    "# #     & ((county_gdf['INTPTLAT'] >= ylimits[0]) & (county_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "# # ].plot(ax=ax, color='none', edgecolor='black', lw=the_line_width)\n",
    "\n",
    "\n",
    "# print('plotting tracts...')\n",
    "# legend_list = []\n",
    "# for i in range(1,9):\n",
    "#     if (tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() > 0):\n",
    "#         #print(i, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum())\n",
    "#         tract_gdf[(tract_gdf['new_district'] == i)].plot(ax=ax, color=district_color_cycle[i], edgecolor='black', linewidth=the_line_width)\n",
    "#         #legend_list.append(mpatches.Patch(color=district_color_cycle[i], label='District {0:,.0f}\\n(n = {1:,.0f} [{2:.1%}])'.format(i, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum(), tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum()/state_target)))\n",
    "#         legend_list.append(mpatches.Patch(color=district_color_cycle[i], label='District {0:,.0f}'.format(i)))\n",
    "\n",
    "# tract_gdf[tract_gdf['new_district'].isnull()].plot(ax=ax, color='none', edgecolor='black', linewidth=the_line_width)\n",
    "\n",
    "# if (label_tracts):\n",
    "#     print('\\tlabeling tracts...')\n",
    "#     tracts_to_label = []\n",
    "\n",
    "#     if (len(places_to_label) > 0):\n",
    "#         print('\\t\\tfinding tracts that overlap chosen places...')\n",
    "#         for this_place in places_to_label:\n",
    "#             print('\\t\\t\\t{0:}...'.format(this_place))        \n",
    "#             tracts_to_label += tract_gdf[\n",
    "#                     (\n",
    "#                         ((tract_gdf['INTPTLON'] >= xlimits[0]) & (tract_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#                         & ((tract_gdf['INTPTLAT'] >= ylimits[0]) & (tract_gdf['INTPTLAT'] <= ylimits[1]))\n",
    "#                     )\n",
    "#                     & tract_gdf.geometry.apply(lambda x: x.within(unary_union(place_gdf[place_gdf['NAME'] == this_place].geometry.tolist())))\n",
    "#                 ].index.tolist()\n",
    "#         print('\\t\\tlabeling tracts that overlap chosen places...')\n",
    "#     else:\n",
    "#         print('\\t\\tlabeling all tracts in this area...')\n",
    "#         tracts_to_label = tract_gdf[\n",
    "#         (\n",
    "#             (tract_gdf['INTPTLON'] >= xlimits[0]) & (tract_gdf['INTPTLON'] <= xlimits[1]))\n",
    "#             & ((tract_gdf['INTPTLAT'] >= ylimits[0]) & (tract_gdf['INTPTLAT'] <= ylimits[1])\n",
    "#          )\n",
    "#         ].index.tolist()\n",
    "\n",
    "#     for ix, thisrow in tract_gdf[tract_gdf.index.isin(tracts_to_label)].iterrows():\n",
    "#         annotator = ''\n",
    "#         #   .apply(lambda row: '{0:}-{1:.0f}'.format(row['COUNTY_NAME'][0:row['COUNTY_NAME'].find(\" County\")], row['census_tract']), axis=1).drop_duplicates().sort_values()    \n",
    "#         annotator += '{0:}\\n{1:,.0f}'.format(thisrow['census_tract'], geo_df.loc[ix]['POP100'])\n",
    "#         centerpoint = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "#         ax.annotate(annotator, centerpoint, \n",
    "#                     color='black', backgroundcolor='white', ha='center', va='center', fontsize=the_annotation_size)\n",
    "\n",
    "# if (show_water):\n",
    "#     print('plotting water areas...')\n",
    "#     water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "# plt.xlim(xlimits)\n",
    "# plt.ylim(ylimits)\n",
    "\n",
    "# plt.xticks(fontsize=the_label_size)\n",
    "# plt.yticks(fontsize=the_label_size)\n",
    "\n",
    "# ax.legend(handles=legend_list, fontsize=the_legend_size)\n",
    "\n",
    "# if (len(list(these_states_dict.keys())) == 1):\n",
    "#     plt.title('New {0:} Congressional Districts (n = {1:.0f})'.format(\n",
    "#         list(these_states_dict.keys())[0], \n",
    "#         these_states_dict[list(these_states_dict.keys())[0]]['seats_new']\n",
    "#     ), fontsize=the_title_size)\n",
    "# else:\n",
    "#     plt.title('New Congressional Districts', fontsize=the_title_size)\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(1, 9):\n",
    "#     if (tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() > 0):\n",
    "#         #if (np.abs(tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() - state_target) >= 1000):\n",
    "#         print('District {0:}: n = {1:,.0f} ({2:.1%} of target; overshot = {3:,.0f})'.format(i, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum(), tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum()/state_target, tract_gdf[tract_gdf['new_district'] == i]['POP100'].sum() - state_target))\n",
    "# print('\\n')\n",
    "# print(tracts_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Towson/Pikesville/Parkville\n",
    "# xlimits = [-76.775,-76.45]\n",
    "# ylimits = [39.35, 39.45]\n",
    "\n",
    "# Pikesville/Garrison\n",
    "# xlimits = [-76.8, -76.7]\n",
    "# ylimits = [39.36, 39.43]\n",
    "\n",
    "# Arbutus / Brooklyn Park\n",
    "# xlimits = [-76.72, -76.6]\n",
    "# ylimits = [39.2, 39.28]\n",
    "\n",
    "# Perry Hall / Honeygo\n",
    "# xlimits = [-76.52,-76.38]\n",
    "# ylimits = [39.36, 39.44]\n",
    "\n",
    "# Gaithersburg\n",
    "# xlimits = [-77.275, -77]\n",
    "# ylimits = [39.05,39.3]\n",
    "\n",
    "# # N Montgomery County\n",
    "# xlimits = [-77.25,-76.95]\n",
    "# ylimits = [39.05, 39.3]\n",
    "\n",
    "# N of Gaithersburg\n",
    "# xlimits = [-77.25,-77.15]\n",
    "# ylimits = [39.1,39.2]\n",
    "\n",
    "# S of Bowie\n",
    "# xlimits = [-76.95,-76.65]\n",
    "# ylimits = [38.85, 38.95]\n",
    "\n",
    "# # Montgomery County near Laurel\n",
    "# xlimits = [-77,-76.835]\n",
    "# ylimits = [39.035, 39.1]\n",
    "\n",
    "# # Northern Anne Arundel County\n",
    "# xlimits = [-76.8,-76.45]\n",
    "# ylimits = [39,39.25]\n",
    "\n",
    "# Gaithersburg\n",
    "# xlimits = [-77.3,-77.15]\n",
    "# ylimits = [39.08,39.2]\n",
    "\n",
    "# # Prince George's DC suburbs\n",
    "# xlimits = [-77.03,-76.83]\n",
    "# ylimits = [38.9,39.13]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
